<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>Samuel Taylor – Blog</title><link>https://www.samueltaylor.org/utm_source=rss&amp;utm_campaign=st-blog-feed</link><description>Building good software is challenging but rewarding. On my blog, I share the things I'm learning as a practitioner in this exciting industry.</description><lastBuildDate>Wed, 03 Jan 2018 12:59:10 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><image><url>/static/img/me.jpg</url><title>Samuel Taylor</title><link>https://www.samueltaylor.org/utm_source=rss&amp;utm_campaign=st-blog-feed</link></image><item><title>Work-Self Balance</title><link>https://www.samueltaylor.org/articles/work-self-balance.html?utm_source=rss&amp;utm_campaign=st-blog-feed</link><description>&lt;p&gt;It's a few months ago. I'm enjoying my job and trying to bring value to my team. A high-visibility project comes up.
Despite being unfamiliar with the framework we plan to use, I'm excited to work on this project. I set out to "learn by
doing", implementing a chunk of the project with this framework. After reading some code, writing some new code by trial
and error, and asking a lot of questions, I'm able to get this chunk finished. More exciting than that, my
implementation serves as a model for much of the rest of the project. Being that I know the framework well at this
point, I'm teaching the rest of the team how to use it. I love knowing that I'm bringing so much value to the team!&lt;/p&gt;
&lt;p&gt;Then, I submit a piece of code for review. One of my team members notices a flaw in it. Immediately, my thoughts rush to
how I can justify the flaw. Underlying this reaction is the belief that this flaw reveals my own incompetence. I start
to type a response. But as I write, I realize that my coworker is right. I thought I knew everything there was to know
about this framework, but clearly I don't. I delete my response and fix the problem instead.&lt;/p&gt;
&lt;p&gt;Since then, I've found a healthier way to think of my work. Let's examine the origins of and problems with my initial
belief so that we can find a healthier alternative.&lt;/p&gt;
&lt;p&gt;The core belief I identify as an issue in the above story is a lack of separation between my work and my self. Creating
software can be a deeply personal enterprise. When I'm in the zone, it can feel like the code I'm writing somehow
emanates from my being rather than that I am actively writing it. Given this understanding, criticism of my work is also
criticism of myself, my character, and my abilities.&lt;/p&gt;
&lt;p&gt;This belief (though not one I consciously chose) is harmful. If criticism is painful, human nature says to avoid it.
Unfortunately, avoiding criticism means avoiding learning because the best learning can come from making mistakes and
fixing them.&lt;/p&gt;
&lt;p&gt;We can choose a healthier relationship to our work. Specifically, I find it helpful to mentally separate my code from my
sense of self. In other words, I avoid tying my ego up in my work outputs.&lt;/p&gt;
&lt;p&gt;This mental model is more true to the realities of software development. On a daily basis, I am faced with countless
constraints. Perhaps I must complete a task within a given timeframe. Maybe I have to use a specific tool. These
constraints mean that the work I produce cannot be considered to be solely a reflection of my character or abilities. In
some way, the work also embodies the constraints I was under while creating it. Given an infinite amount of time and
resources, I'm sure all of us would create impeccable and beautiful software. However, in a world of constraints, our
work is less likely to be perfect.&lt;/p&gt;
&lt;p&gt;How can we rein in our ego? I've noticed that as soon as I am aware that my ego is flaring up, it's easy to see how
silly I'm being. To this end, I've found two activities helpful: journaling and meditation.  Journaling consists of
sitting down in the evening a few times per week and writing about what has happened in the preceding few
days&lt;sup&gt;1&lt;/sup&gt;. By intentionally recalling and reviewing my actions, I'm able to be more objective in my view of
myself.&lt;/p&gt;
&lt;p&gt;Meditation also helps foster the lense of an unbiased observer. When I meditate, I get deliberate, intense practice at
noticing my feelings. Bringing this awareness to the rest of my day becomes easier as I continue this practice. And this
awareness allows me to notice when my ego acts up so that I can respond accordingly&lt;sup&gt;2&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;When I'm able to separate my work from my self, I can respond more productively to criticism of my work. I can see that
the criticism isn't aimed at me. Instead, something I produced was found to be lacking in some way. Previously, I might
waste energy either beating myself up or trying to justify a mistake. But now I can focus on making the necessary
improvement.&lt;/p&gt;
&lt;p&gt;I still love bringing value to my team. But I've realized how crucial it is to stay humble and how valuable it is to
understand that my work is separate from my self. Making a mistake reveals not that I am incompetent, but that I'm
human. And really, aren't we all?&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt;: If you're interested in journaling, I highly recommend Timothy Wilson's
&lt;a href="https://www.goodreads.com/book/show/11516274-redirect"&gt;&lt;em&gt;Redirect&lt;/em&gt;&lt;/a&gt;, which explores a bunch of interesting research in
self narrative.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2&lt;/strong&gt;: I'm sure there are other ways of increasing this kind of self-awareness. &lt;a href="mailto:sgt@samueltaylor.org"&gt;Let me
know&lt;/a&gt; if you have any tips of what has worked for you in the past.&lt;/p&gt;</description><author>Samuel Taylor</author><guid isPermaLink="true">https://www.samueltaylor.org/articles/work-self-balance.html?utm_source=rss&amp;utm_campaign=st-blog-feed</guid><pubDate>Wed, 03 Jan 2018 06:58:11 GMT</pubDate></item><item><title>Poetry for Software Engineers</title><link>https://www.samueltaylor.org/articles/poetry-for-software-engineers.html?utm_source=rss&amp;utm_campaign=st-blog-feed</link><description>&lt;p&gt;&lt;em&gt;This is a modified transcript of episode 3 of &lt;a href="/podcast.html"&gt;my podcast&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="/static/img/poetry_fountain_pen.jpg"&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Photo by &lt;a href="https://unsplash.com/photos/hjwKMkehBco"&gt;Álvaro Serrano&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;I am not a poet. But when I was barely three years old, I was sitting at the kitchen table with my mother and older
sister. They were working on rhyming words, because that is apparently the stage of childhood development my sister was
in. My sister was struggling a little. My mom would ask her, "What's a word that rhymes with ball?" My sister replies,
"bend." Mom says, "No, we're trying to make the end of the word sound the same. So a word that rhymes with ball would be
fall. What are some words that rhyme with sky?" and my sister, with a confused look on her face, replies, "Soon?
Sleep?". Mom says, "No, remember, we want the &lt;em&gt;ends&lt;/em&gt; of the words to sound the same, not the beginning.  So 'fly' or
'pie'. What are some words that rhyme with moon?" she asks. My sister says, "My?" and to hear my mom tell the story, my
little voice pipes up, "Spoon! Loon! June!" which of course prompts my sister to give me an angry look and shout, "Shut
up, Sam!"&lt;/p&gt;
&lt;p&gt;I learned two things that day. First, it is immensely enjoyable to pick on one's older siblings. Second, I learned that
words are interesting. They're fun. I like them. I like the way they sound when you say them and the power they give to
express ideas.&lt;/p&gt;
&lt;p&gt;In the time between that story and now, I've grown to enjoy poetry. This comes as a surprise to some who know me as a
very analytically-minded person. And I get it–I mean, I'm a software engineer. Still, I've found a lot of joy in
poetry. Beyond that, I think it's made me a better engineer.&lt;/p&gt;
&lt;p&gt;Today we're going to talk about why I think you should read poetry. To do this, we're going to talk about how to read a
poem, the ways that beauty is related to software, and a few things we can learn from poets.&lt;/p&gt;
&lt;p&gt;So how &lt;em&gt;do&lt;/em&gt; we read a poem? First, we need to be sure we're in the right mindset. In our culture, it's common for us to
decide whether we like something immediately. For example, a friend of mine went to see the movie Wonder Woman, and I
asked him whether it was a good movie. He replied, "Yeah, I liked it." But that's not exactly what I was asking; the
quality of a piece of art or media is different from an individual's opinion about that piece. When we read poetry, it's
important to understand what it's doing before we decide whether we like it or not. If you decide to read some poetry
after this, I encourage you to read charitably. Try to understand what the author is saying and how she or he is saying
it before you do anything else.&lt;/p&gt;
&lt;p&gt;Once we're in the right mindset, we can dive into reading. For me, it's helpful to have a bit of a process to go
through, and I imagine it can make this a little less weird if you are a so-called "left brain" person. I typically read
through the poem three times:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;On the first reading, I'll pick up a pencil and read through the poem in my head. When I get to any words that I don't
  know the exact dictionary definition of, I circle them. Then I look up these words in a dictionary. Poets spend a lot
  of time choosing the words they use, so it's important to understand what those very specific word choices mean.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Step two is to read the poem out loud. As I'm reading through, when I notice any words that stick out to me, I draw a
  little dot next to them. At this point, I'm not worrying about why they stick out, just keeping note that they do.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;On my third reading, I look for allusion to other work, metaphor, imagery, and other literary devices.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Once I've done these three readings, I'm in a better spot to understand what the poet is saying. Let's do a practice
run. This is a poem by Langston Hughes called "The Negro Speaks of Rivers".&lt;/p&gt;
&lt;p&gt;I’ve known rivers:&lt;br /&gt;
I’ve known rivers ancient as the world and older than the&lt;br /&gt;
    flow of human blood in human veins.  &lt;/p&gt;
&lt;p&gt;My soul has grown deep like the rivers.  &lt;/p&gt;
&lt;p&gt;I bathed in the Euphrates when dawns were young.&lt;br /&gt;
I built my hut near the Congo and it lulled me to sleep.&lt;br /&gt;
I looked upon the Nile and raised the pyramids above it.&lt;br /&gt;
I heard the singing of the Mississippi when Abe Lincoln &lt;br /&gt;
    went down to New Orleans, and I’ve seen its muddy &lt;br /&gt;
    bosom turn all golden in the sunset.&lt;/p&gt;
&lt;p&gt;I’ve known rivers:&lt;br /&gt;
Ancient, dusky rivers.&lt;/p&gt;
&lt;p&gt;My soul has grown deep like the rivers.&lt;/p&gt;
&lt;p&gt;As I read through this, I circled the words "Euphrates" and "Congo"; I know they're rivers, but I'm not 100% on where
they actually are or what they mean. I also circled "dusky", because I don't know the exact definition. Let me look
these up.&lt;/p&gt;
&lt;p&gt;OK, "dusky" means "somewhat dark in color; &lt;em&gt;specifically&lt;/em&gt; : having dark skin". The Euphrates is a river in modern-day
Iraq, and the Congo is in Africa.&lt;/p&gt;
&lt;p&gt;Second reading. In the line "older than the flow of human blood in human veins", I put dots next to both occurrences of
the word human. The word "bathed" in "bathed in the Euphrates" also sounded interesting, so I dotted that. I also dotted
the word "golden" in "I've seen its muddy bosom turn all golden in the sunset".&lt;/p&gt;
&lt;p&gt;Time for the third reading. On this pass, I underline "the Euphrates" as an allusion to the Biblical creation narrative.
"The singing of the Mississippi" is an interesting image, as is "muddy bosom turn all golden in the sunset."&lt;/p&gt;
&lt;p&gt;Now we're in a better place to understand what this all means. Langston Hughes lived in a deeply segregated America, and
I find him making a powerful argument for a sense of common heritage and equality among all people. When he uses the
word "I", he's referring to himself–a black man living in the Jim Crow society of the time. To say "&lt;em&gt;I&lt;/em&gt; bathed in the
Euphrates" is to paint a picture of the first man in the Bible as black. I imagine this was a shocking image to the
society of the time, which had a "One Drop Rule" that meant if a person had even one drop of black blood in them, they
were subject to the brutal segregation of Jim Crow. In this poem, Hughes shows that we are all human, thereby
undermining the subjugating logic of Jim Crow.&lt;/p&gt;
&lt;p&gt;I find this poem to be beautiful. Its construction is clearly well thought out, and the story it tells is a persuasive
argument against segregation. But it may seem like we're on a bit of a rabbit trail here–how does any of this relate to
software? Allow me to answer your question with a story.&lt;/p&gt;
&lt;p&gt;Have you ever heard of "fizz buzz"? It's a well-known interview question in which you're supposed to print out the
numbers 1 through 100, except when a number is divisible by 3 print "fizz", when it's divisible by 5 print "buzz", and
if it's divisible by both print "fizz buzz". So the sequence goes 1, 2, fizz, 4, buzz, fizz, 7, 8, fizz, buzz, 11, fizz,
13, 14, fizz buzz, and so on.&lt;/p&gt;
&lt;p&gt;The specific code to solve this problem could take a variety of shapes, but a straightforward Python implementation took
around 9 lines. By contrast, there's a satirical GitHub repository called &lt;a href="http://www.fizzbuzz.enterprises"&gt;Fizz Buzz Enterprise
Edition&lt;/a&gt; that consists of 1,387 lines of Java code spread across 89 files. Fizz Buzz
Enterprise Edition is an exercise in using every design pattern you possibly can regardless of whether it actually
improves the code.&lt;/p&gt;
&lt;p&gt;I gave a presentation on the subject of poetry to some coworkers at one point, and I showed them the 9-line Python
script followed by a single one of those 89 files in the Enterprise Edition. I asked them, "Which of these codebases is
better?". The response was unanimous, of course: the Python script was better. When I asked them why they thought so, it
took only a few seconds for someone to say the word "elegant." &lt;/p&gt;
&lt;p&gt;And therein lies the answer to your question. When we start talking about what makes good code, the discussion quickly
gets to the idea of "elegance", which I would say is a specific way of talking about beauty. In the software industry,
we like to think of ourselves as innovators creating novel inventions, but when we start talking about beauty, we're
incredibly late to the party. While some in this industry lambaste the humanities as useless, human beings have been
trying to understand beauty for thousands of years. We would be foolish to throw away all we've learned.&lt;/p&gt;
&lt;p&gt;Being a great engineer involves writing great software. And ideally, our software is elegant and beautiful. To get a
sense for what those terms mean, we can turn to poetry. I've found that as I read more poetry and understand how it's
constructed, I'm able to apply that knowledge to structuring my team's software. Understanding the way that a poet
specifically chooses her or his words to fit the intention is fascinating and informs the way I choose to name
functions, variables, and classes.&lt;/p&gt;
&lt;p&gt;This takes us into our third point: we can learn a lot from poets. One day, the poet Ezra Pound was sitting in a subway
station in Paris. As he looked around at the people walking through the station, he was overcome by a unique feeling.
Like any good poet, he strived to capture that emotion in a poem. His first version was 30 lines. After six months, he'd
carefully crafted and whittled it down to 15 lines. A year later, he published the poem &lt;em&gt;In a Station of the Metro&lt;/em&gt;,
which reads:&lt;/p&gt;
&lt;p&gt;The apparition of these faces in the crowd;&lt;br /&gt;
Petals on a wet, black bough&lt;/p&gt;
&lt;p&gt;Whether you like this poem or not, it's impressive in its ability to convey an image and an emotion by connecting two
seemingly unrelated images. In the process of slowly and carefully carving away the excess and cruft from the poem,
Pound is able to compress a lot of information into fourteen words.&lt;/p&gt;
&lt;p&gt;We should strive to be more like poets. Good poets are able to express their ideas in precise language that communicates
clearly. A huge part of the way they do this is by choosing their words carefully. This process is directly applicable
to our work creating software. We're trying to encode some real-world process or use case into code that communicates
our intentions to future maintainers. If we're sloppy with the way that we name things or structure our programs into
functions, classes, or packages, the things we create will do a much worse job communicating the idea we have in our
head to future maintainers.&lt;/p&gt;
&lt;p&gt;Poetry is a useful hobby for software engineers. By helping us to better understand beauty and communication, poetry
helps us develop skills that are directly applicable to creating good software.&lt;/p&gt;
&lt;p&gt;I want to leave you with one last poem. Before I read this, I'm going to ask you to do something. I'm not trying to be
manipulative, but I'm hoping to help you understand this author better. Take a few moments and think of someone who
means a lot to you; it could be a family member or a close friend, but think about all the things that they mean to you
and ways they improve your life.&lt;/p&gt;
&lt;p&gt;The Gate, by Marie Howe&lt;/p&gt;
&lt;p&gt;I had no idea that the gate I would step through&lt;br /&gt;
to finally enter this world&lt;/p&gt;
&lt;p&gt;would be the space my brother's body made. He was&lt;br /&gt;
a little taller than me: a young man&lt;/p&gt;
&lt;p&gt;but grown, himself by then,&lt;br /&gt;
done at twenty-eight, having folded every sheet,&lt;/p&gt;
&lt;p&gt;rinsed every glass he would ever rinse under the cold&lt;br /&gt;
and running water.&lt;/p&gt;
&lt;p&gt;This is what you have been waiting for, he used to say to me.&lt;br /&gt;
And I'd say, What?&lt;/p&gt;
&lt;p&gt;And he'd say, This—holding up my cheese and mustard sandwich.&lt;br /&gt;
And I'd say, What?&lt;/p&gt;
&lt;p&gt;And he'd say, This, sort of looking around.&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;Thanks for reading. I would love for you to tweet your favorite poem to me; I'm
&lt;a href="https://twitter.com/SamuelDataT"&gt;@SamuelDataT&lt;/a&gt;. Now get out there and read some poetry!&lt;/p&gt;</description><author>Samuel Taylor</author><guid isPermaLink="true">https://www.samueltaylor.org/articles/poetry-for-software-engineers.html?utm_source=rss&amp;utm_campaign=st-blog-feed</guid><pubDate>Sun, 10 Dec 2017 16:33:25 GMT</pubDate></item><item><title>Monte Carlo Simulation with Categorical Values</title><link>https://www.samueltaylor.org/articles/monte-carlo-categorical.html?utm_source=rss&amp;utm_campaign=st-blog-feed</link><description>&lt;p&gt;We live in a world of imperfect information. When faced with a lack of data, we can make a guess. This guess could be
far from the truth; it could be spot on. In Monte Carlo simulation, we repeatedly make guesses of some unknown value
according to some distribution and are able to report on the results of that simulation to understand a little bit more
about the unknown. While any one guess may be far from the truth, in aggregate those outliers don't have as much of an
effect.&lt;/p&gt;
&lt;p&gt;I ran into a situation where I was gathering some data with some level of imperfection. My stakeholder wanted to know
what the impact of that imperfection on the important metrics would be. I could have made a guess, but instead I turned
to the data. Initially, I thought to calculate the best case and worst case scenarios. This idea is useful in that it
gives you a range on what you don't know, but it's also beneficial to know how likely each of those scenarios (and
things in between) are. That's where Monte Carlo simulation comes in handy.&lt;/p&gt;
&lt;p&gt;For the purposes of context, let's use a contrived example. Suppose I run a car dealership, and a major hail storm
rolled through last weekend. Some of my cars suffer major damage and will incur a 10% loss in their value, some suffered
minor damage incurring a 5% loss, and some suffered no damage at all. I don't have enough labor to survey every single
one of my cars, but I do want to know how much money I can expect to lose. I randomly select 500 of my 1000 cars and see
how bad the damage was.&lt;/p&gt;
&lt;p&gt;Hypothetically, it's possible that the 500 cars I inspected were the only ones that happened to have been damaged by the
hail (maybe the rest were safe in my 500-car warehouse). That would be the best case scenario, in which case I suffer
only the loss on the cars I inspected. In the worst case scenario, every car I didn't inspect suffered major damage. For
some random data I generate below, we know that the amount of damage done to the uninspected cars is somewhere between 0
and around $1.75 million dollars. This is a huge range of possibilities!&lt;/p&gt;
&lt;p&gt;We see that looking at the best case and worst case gets us some bounds on how bad the damage could be, but we have no
idea how probable each of these options are (let alone the probability of the values in the middle). To find out how bad
the damage is likely to be, we can turn to Monte Carlo simulation.&lt;/p&gt;
&lt;p&gt;First, let's randomly generate our inventory, then inspect half of our cars. While we know the &lt;code&gt;value&lt;/code&gt; of each car, we
think of the &lt;code&gt;damage_pct&lt;/code&gt; as an unknown value for the cars we do not inspect.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;

&lt;span class="n"&gt;N_CARS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1000&lt;/span&gt;
&lt;span class="n"&gt;cars&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;
    &lt;span class="s1"&gt;&amp;#39;value&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;normal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;35000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;N_CARS&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
    &lt;span class="s1"&gt;&amp;#39;damage_pct&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;choice&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.05&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;N_CARS&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.4&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="p"&gt;})&lt;/span&gt;

&lt;span class="n"&gt;inspected_cars&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cars&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sample&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cars&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;//&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;uninspected_cars&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cars&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;~&lt;/span&gt;&lt;span class="n"&gt;cars&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;isin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inspected_cars&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;

&lt;span class="n"&gt;damage_dist&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inspected_cars&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;groupby&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;damage_pct&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
               &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;inspected_cars&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rename&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;value&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;prob&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;We can see the distribution of &lt;code&gt;damage_pct&lt;/code&gt; among the sampled cars is&lt;sup&gt;1&lt;/sup&gt;:&lt;/p&gt;
&lt;table&gt;
&lt;tr&gt;
  &lt;th&gt;damage_pct&lt;/th&gt;
  &lt;th&gt;prob&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td&gt;-0.1&lt;/td&gt;
  &lt;td&gt;0.096&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td&gt;-0.05&lt;/td&gt;
  &lt;td&gt;0.490&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td&gt;0.00&lt;/td&gt;
  &lt;td&gt;0.414&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;Because we inspected a random subset of the cars, a reasonable simplifying assumption is that the damage to the
uninspected cars has the same distribution as that of the inspected cars. With that assumption, we can simulate the
damage done to the uninspected cars like so:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;simulate_damage&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;damage_dist&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;uninspected_cars&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;damage_pct_guess&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;choice&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;damage_dist&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                        &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;uninspected_cars&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                                        &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;damage_dist&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;prob&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;damage_pct_guess&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;uninspected_cars&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;N_SIMULATIONS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1000&lt;/span&gt;
&lt;span class="n"&gt;simulated_damages&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Series&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;simulate_damage&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;damage_dist&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;uninspected_cars&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                               &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;N_SIMULATIONS&lt;/span&gt;&lt;span class="p"&gt;)])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;To make sense of the output of these 1000 simulations, we can calculate some descriptive statistics. It's also helpful
to look at the CDF of the simulated damage.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;simulated_damages&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;describe&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;span class="n"&gt;simulated_damages&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;kind&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;hist&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cumulative&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;bins&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                       &lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;CDF of estimated damage&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre&gt;&lt;code&gt;count      1000.000000
mean    -595662.074433
std       25097.417355
min     -671499.963571
25%     -613690.059583
50%     -595382.298010
75%     -576089.086686
max     -524043.037134
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src='/static/img/mcs_cdf.png'&gt;&lt;/p&gt;
&lt;p&gt;We can say that in half of our simulations, the damage was somewhere between $671,499.96 and $595,382.30. This range is
about 4.3% the size of the range between the best and worst case scenarios.&lt;/p&gt;
&lt;p&gt;How'd we do? Because we made up the dataset, we can calculate the true value and put that number on the graph above:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;true_damage&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;uninspected_cars&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;uninspected_cars&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;damage_pct&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;bottom&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;top&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylim&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;annotate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;xy&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;true_damage&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;top&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;xycoords&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;data&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
             &lt;span class="n"&gt;xytext&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;true_damage&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;bottom&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;textcoords&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;data&amp;#39;&lt;/span&gt;
             &lt;span class="n"&gt;arrowprops&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;dict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;facecolor&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;red&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;headlength&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src='/static/img/mcs_cdf_wtruth.png'&gt;&lt;/p&gt;
&lt;p&gt;In "reality", the true amount of damage done was $607,830.94, which just so happens to be in that window of 50% of our
simulations.&lt;/p&gt;
&lt;p&gt;We can run this experiment a few more times to see how this method fares:&lt;/p&gt;
&lt;p&gt;&lt;img src='/static/img/mcs_many_cdf.png'&gt;&lt;/p&gt;
&lt;p&gt;The next time you're trying to reason about some unknown value, consider using Monte Carlo simulation to inform your
decision-making process.&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;1: While the values for &lt;code&gt;damage_pct&lt;/code&gt; look like numerical data, remember that they are representative of the three
categories of damage sustained (none, minor, or major).&lt;/p&gt;</description><author>Samuel Taylor</author><guid isPermaLink="true">https://www.samueltaylor.org/articles/monte-carlo-categorical.html?utm_source=rss&amp;utm_campaign=st-blog-feed</guid><pubDate>Sun, 03 Dec 2017 09:55:29 GMT</pubDate></item><item><title>Use Machine Learning to Find your Next Job</title><link>https://www.samueltaylor.org/articles/use-machine-learning-to-find-your-next-job.html?utm_source=rss&amp;utm_campaign=st-blog-feed</link><description>&lt;div class="embed-responsive"&gt;&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/HR1ptrLMxA0" frameborder="0" allowfullscreen&gt;&lt;/iframe&gt;&lt;/div&gt;

&lt;p&gt;Delivered at:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.devspaceconf.com/"&gt;DevSpace&lt;/a&gt; on 14 Oct 2017. Audio available on &lt;a href="/podcast.html"&gt;my podcast&lt;/a&gt;. Slides
  available &lt;a href="/static/pdf/find_job_ml.pdf"&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://datascicon.tech/"&gt;DataSciCon&lt;/a&gt; on 30 Nov 2017. Slides available &lt;a href="/static/pdf/datascicon_find_job_ml.pdf"&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Transcript&lt;/h2&gt;
&lt;p&gt;A wise man once said, "I got ninety-nine problems," and I can relate to that in some sense. Because on a day to day
basis I run into problems; I run into things that aren't as easy as they should be or things that I want to be better.
And I suspect that because you are all in this room on a Saturday you also have problems, you also run into things and
want to use software to solve them. Today I want to talk about ways that we can use software to solve our problems and
specifically to give those software solutions some intelligence using data.&lt;/p&gt;
&lt;p&gt;Now the motivating example and the one for which this talk is titled is a job search helper thing that I made. Basically
what happened was a few months ago I was passively job searching, which is to say that I wasn't actively out there
knocking on people's doors and handing out résumés, but I was curious to see if there were any particularly excellent
jobs in my area. I went out and tried to sign up for different job alert things that would give me the coolest jobs and
I couldn't find anything that did exactly what I wanted it to do. Like any good Engineer I decided to build it myself. I
built this little email newsletter that I would send to myself every week that essentially had the coolest sounding jobs
in my area. I could go through and just review those jobs. It was basically a way to filter out a lot of the noise. And
so we're going to use this as sort of a case study today, to talk about a process that I've gotten to use a few times
that has worked for me. I wanted to share it with you all to hopefully provide some value in your own lives.&lt;/p&gt;
&lt;p&gt;So this is how we're going to be doing that, the astute among you have probably noticed we are currently in the
introduction. After that we're going to talk about asking the right question; basically phrasing questions in ways
computers can help us answer them. Once we do that we'll talk about ways to gather the data, and then we'll analyze the
data. Finally, we'll deploy the insights that we gather, and here I don't mean deploy in the sense of we're going to put
the code on a server somewhere. That part is interesting, but more relevant to this discussion is how do we get a number
to be something interesting to a person and express in a way that people can understand it.&lt;/p&gt;
&lt;p&gt;So as for me I'm originally from this part of California (Bakersfield, CA). It's the really boring part, but it was a
great place to grow up, and then I left and went to Baylor University where I studied Computer Science. I really enjoyed
my time there, and while I was there I sort of got bit by the data bug and got to do some research in an autonomous
drone lab that was really exciting, do some research with collaborative filtering (which is a recommender systems kind
of thing) that got me started down the path of the thing that I ended up building for this.  Another relevant thing I
got to do while I was there was I taught a computer sign language which was really fun. And then over the summers I
would go do internships in various places and learn a lot about software and good engineering practices. I tried to
unify this all together, and then after I graduated went and started doing some data engineering work, and now I
actually work at Indeed (which is the world's largest job site).  Interestingly enough literally everything that I'm
going to talk about today is completely unrelated to my job there (other than the fact that I do data stuff there too)
but all the code that I wrote for this I actually wrote while I was at my prior company. But the most important thing on
this map is the fact that we're all here in this room today to talk about this stuff, and I'm really glad that you are
all able to come and honored by your presence here today.&lt;/p&gt;
&lt;p&gt;So that's all the boring stuff–let's get in to the cool part! The first step in this process is to have a problem. This
is the easiest step because it's the one that just comes naturally. It's the one that you bump into on a day by day
basis. For me, I bumped into the problem that job alerts are too noisy. There's too many jobs for me to reasonably look
over in a short amount of time. I've also run into problems where I was trying to figure out how to get my energy bill
lower or trying to figure out how to get home from work faster. Once you have a problem the next thing you're going to
want to do is start to think about solutions. In order to do that, you need to understand the ways we can ask computers
questions and get useful answers back from them, which leads us to the fun buzzword of the day: Machine Learning.&lt;/p&gt;
&lt;p&gt;If you have heard the phrase "Machine Learning" please raise your hand. Alright, yeah it's a buzzword we've all heard.
If you feel like you have used machine learning in a substantial or interesting way, raise your hand. Awesome, some more
great hands. Alright, one last question: if the phrase approximation-generalization tradeoff means anything to you,
please raise your hand. That's fine we'll talk about it later, I just wanted to know what to go into. Thanks for your
participation there.&lt;/p&gt;
&lt;p&gt;So what is machine learning? There are a few different things that comprise it, and I'm going to talk about a subset of
it today. There are a few kinds of algorithms broken into a lot of different categories, but this is good enough for
today. There's a type of algorithm called a supervised algorithm in which you are basically feeding training data into a
computer. That training data has a number of features that are like input values and then a number of output variables.
Here on this graph what you see is that the X axis is age and the Y axis is net worth. The example problem here is
basically: I'm a bank and people are coming to me asking for a line of credit. I'm trying to decide whether to extend
them a line of credit or not. One way you could theoretically do this is to just look at your past history and say,
"Okay when people have come to us in the past and asked for credit, how old were they? What was their net worth? And did
we extend credit?" That's what this graph is displaying: the age and then the net worth. The plus or minus you can think
of as a one or zero of whether or not we extended them a loan. And then the machine learning part of this is basically
draw a line through this data. It doesn't have to be a line but a line works for this so we're just drawing a line. And
you'll see here that because in the past we had someone who is ninety and did not have very much money who came to us
and asked for a loan and we rejected them, if someone who is similarly aged and similarly wealthy came to us, they will
be below this line, so we would not extend them a line of credit. That is an example of a classification problem,
because there are classes involved. There is a "positive" (we did extend them a loan) or a "negative" (we didn't extend
them a loan) kind of question. Classification is great for when you're trying to find out what kind of thing something
is.&lt;/p&gt;
&lt;p&gt;Now, if I were a bank trying to decide how much credit I should extend to a person, I would have to use a regression
algorithm. Regression is very similar to classification in that you still have a number of input features and an output
of some sort. Here it's a little bit confusing because here only the X axis is an input. On this last slide both X and Y
were inputs and then the plus and minus was the output, but here we're just saying that the X axis is our input of net
worth. Someone comes up to us and they say, "I have five hundred thousand dollars, how much of a loan can I get?" The
"X" symbols aren't significant (they're just to mark position), but you can see (for instance) someone who had very high
of a net worth down near that bottom left hand corner only got a loan of a thousand dollars because that was a more
risky person (for instance). As a bank, I have all this historical data, and I can train some sort of algorithm that
would again draw a line, and we could then say if someone comes up to us and has a seven hundred fifty million dollars
net worth we can look at where they would land on the X position of the line.  Then the Y value then would be the size
of loan we extend them. Here it looks like seventy five thousand dollars or something. So that is another kind of
supervised machine learning algorithm.&lt;/p&gt;
&lt;p&gt;There are also unsupervised algorithms. One such algorithm is called clustering and in clustering you have a bunch of
data points, and I apologize that this is not the same example, but you can imagine that each of these dots is a
customer. The X axis could again be their age and Y axis could again be the net worth. Maybe it's computationally
prohibitive to do the calculation on the full data set, but you could theoretically cluster people and say there are
(for instance) eleven kinds of people. Then, depending on the kind of person you are, we could make a decision based off
of that. In clustering, you're not trying to get a specific output, you're just trying understand the data better. It's
often useful as a preprocessing step. You might again have someone come in and they have a certain net worth and certain
age. You could say this person is really similar to this other kind of person that we usually extend a credit to, so
let's extend credit this person.&lt;/p&gt;
&lt;p&gt;There's a lot of other stuff in the field of machine learning that is time prohibitive to talk about today. So this
third of this slide is here to prevent angry tweets because there's a lot of stuff that is really interesting that just
doesn't quite fit in today.&lt;/p&gt;
&lt;p&gt;So once we know the kinds of questions we can ask a computer, we can figure out a way to phrase our question. In my
example, I'm thinking, "OK, job alerts are too noisy for me. What do I want? I want to know what are the coolest jobs.
OK, well maybe I can ask a computer. Given my input of a job title, give me the output: does it sound cool or not (just
as a one or a zero)." And that's a way we can phrase our question in a way a computer can actually help us with. So now
that we have this formulation of our problem, we can jump into gathering our data.&lt;/p&gt;
&lt;p&gt;There's a lot of data out there, and the best thing to do is just search for it. Go out and Google it. For instance, one
time I was trying to determine my energy usage, and I thought it was probably going to be correlated with weather. I was
looking for weather data, and there is this government agency called the NOAA that has a big weather data set that you
can just download and use. And so it's very likely that you'll get out there and search for something and there's
already a government agency whose job it is to collect this data, which is really exciting because it means you then
have to do less work. In the case where you don't find something that already exists through searching, you can also try
various websites. data.world is one, Kaggle datasets also has a similar feel where they have a bunch of existing
datasets about usually more broad things. They don't tend to be a specifically relevant if that makes sense, although
they'll have things like crime data on their website. That may or may not be useful to you, but if if you're trying to
figure where to buy an apartment and you want to look at crime statistics, that dataset might already exist.&lt;/p&gt;
&lt;p&gt;So you may or you may not find the data you need, and if you don't you're going to have to create it at some point. I
like using spreadsheets for this because I can have them on my computer and I can have them on my phone, and anywhere I
am I can collect more data. Other than that there's a tool called If This Then That that can be useful, especially when
you're collecting data on your own personal habits. For instance, when I was trying to find out when the best time to
leave my office was to minimize my commute time, you can get a little button that IFTTT will make for you where when you
click it, it'll log your location and the current time to a Google Sheet. So what I would do was when I left the office,
I would press the button then when I got home I would press the button again. In that way I could calculate how long it
took me to get from my office to my home and at what time I left. And then I could have all this data about, okay you
can leave at this time (that's your input value) and it took you this long (that's the output value). Now I know that
Google Maps can also do this for me, but I'm a nerd and we are at a developer conference so I think it's fair to
over-engineer something.&lt;/p&gt;
&lt;p&gt;Beyond that, web scraping is another great tool. What this basically is downloading a website and picking out the
important bits. There are some legal things here, and I am not a lawyer, so do your own lawyer stuff but an important
tip is that when you're trying to scrape a website, look at their robots.txt. Whatever a website you're on, take the
domain name and put &lt;code&gt;/robots.txt&lt;/code&gt; and it'll have a listing of thing of basically the places you're not supposed to go if
you are a computer. Please obey that and you're probably fine, but again I'm not lawyer and this is not legal advice.&lt;/p&gt;
&lt;p&gt;And maybe the case is that you combined these two methods. That's exactly what I am doing in this project. I web scraped
a bunch of job titles, and then when I had spare time on the bus or something I could click through the links on my
phone, read the description and come back to say whether or not the jobs sounded cool. Columns A through D here are
existing data and then column E is the augmented data that I'm creating myself.&lt;/p&gt;
&lt;p&gt;You're going to need to clean this data.  I heard someone speaking at a conference and they said, "Fifty percent of data
science is cleaning data." And when he got done he had all these people coming up to him that said, "That's ridiculous!
At my job it's eighty percent!" There's two tools that I highly recommend if you're in the Python ecosystem: Pandas
(which does a great job of loading data into a tabular format in memory). I've heard it described as "in memory SQL".
And then scikit-learn has some stuff built in to massage data into a format that computers can more easily understand
that we'll get to in a moment.&lt;/p&gt;
&lt;p&gt;Now you may remember this graph from before that had numeric data. Computers are good at numbers; computers aren't as
good at words.  You may think, "Well, if I had someone's age and net worth, I easily see how those are just numbers. But
for something like a job title, that is different. That doesn't feel like I can just type that into a computer and have
it fit that into a graph because I I don't even know how that mapping would work. And so we want to introduce something
where we take as input the job title and as output whether or not it sounds cool, then turn it into some set of numbers.
The great thing is that when you run into a problem like this there are a wealth of giants whose shoulders you can stand
upon. You can just Google "text representation for machine learning" and out will pop this probably. This is the idea of
word count vectors or "bag of words." Essentially what's happening here is you'd take all of your job titles and you
keep track of either all of the words that were used in every single one or maybe the three hundred that are used most
frequently. Then you stack them all up, go through each job title, and count that how many times each word occurred in
the given job title. So we can see for this first job title "Senior Web Applications Developer" that the word "Engineer"
occurs zero times in this job title and the word "Web" occurs one time, etc. I'm not going to bore you by enumerating
this matrix but you see how this process works. "Word count vectors" is a fancy way of saying strings of numbers that
count up how many times a given word is in a given job title, and that gives us exactly what we're looking for. We can
now go from the job title and the output variable (of whether or not it sound cool) to this set of numbers where these
first ten numbers are the number of times a given word occurs (so maybe that first number is "senior") and that last
number there is a one because that job title sounded cool to me.&lt;/p&gt;
&lt;p&gt;And so now can start actually analyzing this data which is great. There's a few tools that I recommend for doing this
kind of work. Jupyter is really great; it's an interactive programming thing. Essentially you run it on your computer,
and you can load a browser up and do stuff, and it'll show you the output of it immediately (which is super helpful).
It's nice being able to see what the data looks like and it's nice to be able to understand what your next step should
be. You can also do neat things like drawing graphs, such as the one shown in this screenshot. The maintainers of this
project have put a ton of work to make it basically the de facto, interactive, iterative programming tool for data
science and data analysis people who are using Python. I spend a lot of my day in Jupyter Notebooks at work.&lt;/p&gt;
&lt;p&gt;I also definitely recommend Pandas and scikit-learn (which we talked about earlier). It's nice to not have to
re-implement all these algorithms from scratch because other people have already done it for you.&lt;/p&gt;
&lt;p&gt;So this is just a little code example to show you how easy this kind of stuff can be. Often times we talk about machine
learning and it sounds really scary and foreign. But when you actually look at the code you'll realize this is something
anyone can do. This is not complicated, it's just a little bit of understanding how these algorithms work and then
reading some documentation. I often call things X and Y because I'm just used to that nomenclature so I take our job
titles out of the dataset that I have and I put them into this X matrix. I take whether or not this sound cool and put
that in this Y vector. The next line is a CountVectorizer (it just does that word counting thing that we were talking
about earlier) and then you can just say, "OK, take this matrix and turn it into the word counts." Then you create a
model, you fit the data to it and then you can just call &lt;code&gt;.predict&lt;/code&gt; on it and it will give you this beautiful array
(that I have here bolded) that says, "Job zero did not sound interesting, and then job four does sound interesting." You
can get this all out very easily; it's not a lot of code to get a lot of value.&lt;/p&gt;
&lt;p&gt;The thing you want to do after you've been able to gather your data is just do the simplest thing that could possibly
work.  There's good reasons for doing this. Earlier, no one knew what the Approximation-Generalization Tradeoff was. My
hope is that you are about to learn. The idea here is that the better your algorithm approximates the input dataset, the
worse it is going to do at generalizing to data that is outside of your input data.  That's a little hard to just say
and have it be understood, so I made a little graph that I think will help. In the process of making this graph, I first
generated a true dataset. You can see here the blue line and this basically says that when we enter zero the value that
comes out is zero, and then at the far right end of the scale when we entered ten we expected negative twenty two out.
It is a very simple function that we're trying to estimate with our machine learning stuff (it's purely for
illustration). And you can see then I generated ten data points from this blue line by just adding a little bit of noise
to each point because the real world is fairly noisy for a number of reasons.  And then I fit two different models. The
red line is a nearest neighbor model (which is a more complicated model than the linear regression model,) and you can
see that it does an excellent job of representing the dataset that we gave to it.  It is matching perfectly at every
single data point there which is great, but you can also see that it is not very close to the truth. If you were to draw
more data points from the same truth we would basically find that the red line isn't doing a good job of generalizing to
data that it has not seen yet. This would be like if you were taking a practice test for a math class and all you did
was memorize the right answers to each question. You would do great at the practice test, but once you got to the real
test you would do horribly (because you don't know actually know how to do any of it, you just know the right answers).&lt;/p&gt;
&lt;p&gt;By contrast linear regression is doing a much worse job of approximating the input data set.  If you see for X value
equal zero it's roughly five units underneath that data point and similarly from the range like two, three, four it's
not doing a great job either of approximating the input data.  However one thing that you'll notice is that line on
average looks a lot closer to the truth than the red line does and the reason is that it is better able to generalize to
out of sample data. What we can see here is that the red line is doing what is called overfitting, which is when you
learn too much of the noise in your algorithm.  And that's a real problem that is easy to run into, especially when
you're using complicated methods. There's a lot of really interesting stuff on Hacker News that will have you believe
that you should use TensorFlow and PyTorch and all these really interesting and exciting deep learning frameworks. And
they are all very interesting and very exciting and have great applications, however they are often more prone to
overfitting than some simpler models. So it's great to just start with something simple and you can move on from that if
you need to.&lt;/p&gt;
&lt;p&gt;Another benefit is it often just easier. It's a lot easier to get scikit-learn running on a Mac or a Windows computer
than it is to get PyTorch or TensorFlow running. Aside from that, when you're iterating through this development process
it's a lot easier to have something that trains really fast and you can try out a bunch of different ways of
representing your data or different ways of sampling it (and have that be fast) rather than something that takes a long
time to train. In practice with this means is just start with something simple, linear regression and logistic
regression are both great models that are good places to start and you can use them both for regression or
classification.&lt;/p&gt;
&lt;p&gt;So we've gotten to the point here with this that we're in the deployment process. By this I mean that we have these
numbers right? We got those numbers out of our model (the zero and the one), but if I were to just look at zero, one,
zero, one, zero, zero, one, that doesn't do anything for me. And I also don't want to have to run that code myself every
time so one thing that I was thinking (because I am my own user, and I can kinda read my own mind) was I wanted to build
this email which you already saw earlier (spoiler alert, sorry) but basically the thought is I don't want to run this
thing on my own and I want to get just the relevant and interesting jobs. So what I did was just put it onto a server
that I rent and have it run every week, and then send me just the jobs that are interesting. It formats them a little
nicely and puts them into an email and sends them off to me. And this is a good thing to do is just build something
simple and ship it. Get it working, because the next step here (and if you've gone to any of talks that people have been
doing about agile practices this should sound familiar. Because just because we're using data in the software does not
make it any less software) is to test out our product. We still need to test out our product, we still need to try it on
actual users, we still need to figure out what doesn't work and what does work, we still need to iterate and we still
need to iterate again and try something new. And we need to iterate even another time, and we just keep moving and keep
trying new things until we get to something that works really well.&lt;/p&gt;
&lt;p&gt;So to summarize because that was a good amount of things:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Step one is to have a problem. Find something that you want to solve that sucks in your life&lt;/li&gt;
&lt;li&gt;Once you have that thing, phrase it in a way that a computers can help you answer it. There's a lot of things
   computers are good at. If you have a problem that you can rephrase as a "how much?" or "what kind of?" problem, those
   are really great candidates for a machine learning application.&lt;/li&gt;
&lt;li&gt;Once you do that, you're ready to get some data.&lt;/li&gt;
&lt;li&gt;Try the simplest thing you possibly can and see how well that works. You can test out and iterate from there. But
   it's really important to get this in front of users and to just try new stuff.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;So that is the gist of what I have for you today.  If you want to learn more, there's a text book called Learning from
Data that is really excellent. It does a good job teaching machine learning in a good way. A lot of times when people
talk about machine learning, it comes off as a bag of tricks, but this book does a good job of helping you understand
some of the theoretical underpinnings that help make these algorithms work. And then from a less academic but more
practical side there's a blog called Practical Business Python where the author talks a lot about data visualization and
how to do useful stuff with Pandas and it's extremely useful when you're trying to learn this stuff.&lt;/p&gt;
&lt;p&gt;Also sponsors are good. We like them. If you are looking for a job I'm sure some of these people are hiring, and we're
very grateful to have them here. I would be remiss not to thank my employer (Indeed) because they paid for me to be here
so thanks for that. Other than that I hope that you've gotten something out of today and would love to meet you all
after. If you have any feedback: if it's negative please email me; I would love to hear what I can do to make this
better. If you have any positive feedback please tweet it. &lt;/p&gt;
&lt;p&gt;I hope you've gotten something out of today and are better able to go solve your problems.&lt;/p&gt;</description><author>Samuel Taylor</author><guid isPermaLink="true">https://www.samueltaylor.org/articles/use-machine-learning-to-find-your-next-job.html?utm_source=rss&amp;utm_campaign=st-blog-feed</guid><pubDate>Sat, 11 Nov 2017 19:42:33 GMT</pubDate></item><item><title>To become a great Python developer, quit reading Python books</title><link>https://www.samueltaylor.org/articles/quit-reading-python-books.html?utm_source=rss&amp;utm_campaign=st-blog-feed</link><description>&lt;p&gt;Learning is a crucial part of being a software developer. Increases in knowledge and skill can make a significant impact
in our work. But in an age where everyone seems to be in a time crunch, we want our learning to be as effective as
possible. We want to get as much learning out of our books, courses, and videos as we can. Counterintuitively, I believe
one of the best ways to maximize knowledge gain is by reading books that do not apply easily to technologies or concepts
we already understand.&lt;/p&gt;
&lt;p&gt;(Prefer to listen? &lt;a href="/podcast.html"&gt;Subscribe to my podcast&lt;/a&gt; for a narrated version.)&lt;/p&gt;
&lt;p&gt;Over the last year, I've read two books that aren't written in Python (the primary language I use at work): &lt;em&gt;Working
Effectively with Legacy Code&lt;/em&gt;, by Michael Feathers, and &lt;em&gt;Practical Object-Oriented Design in Ruby&lt;/em&gt; by Sandi Metz.
Initially, I was skeptical as to whether I would gain much from them, as specific tactics seemed like they wouldn't be
applicable outside the language the author chose to use for each book. To my surprise, I learned &lt;strong&gt;more&lt;/strong&gt; from these
books precisely because they were not written in the primary language I use.&lt;/p&gt;
&lt;p&gt;I find three reasons for this. The first is that reading unfamiliar languages causes my brain to comprehend the material
better. Because I don't know Ruby at all, I have to put in more work to understand the text. When I read a snippet of
Python code in a book, I'm more likely to skim. But when I come across a bit of C++, my brain has to focus to really
understand how the code works.&lt;/p&gt;
&lt;p&gt;The second reason I think these books had an outsized contribution to my development skills is that they caused me to
think through the way to apply the ideas in a new context. While reading about how to make a well-designed Ruby class
that was amenable to testing, I was thinking about how to apply those lessons in Python. To be clear, I had to choose to
do this. And if you want to maximize your learning, you'll have to do the same. By forcing my brain not merely to
understand the information, but to also apply it in a new context, I learned the material more thoroughly.&lt;/p&gt;
&lt;p&gt;The final reason I think these books were so helpful is that they are great books. Kind of obvious, right? A
well-written book is more helpful than a poorly-written book. When we limit ourselves to just the materials relevant to
our day-to-day work, we miss out on gems written in other languages. Plenty of excellent books that can help us become
better software engineers exist; we shouldn't exclude some simply because of the language their author chose to use for
them.&lt;/p&gt;
&lt;p&gt;Putting ourselves in unfamiliar situations is hard. Because of that difficulty, it also has a huge potential to bring
about learning and growth. Pick up a book in a language you don't know and thoroughly study it–you may be surprised by
how much you learn.&lt;/p&gt;</description><author>Samuel Taylor</author><guid isPermaLink="true">https://www.samueltaylor.org/articles/quit-reading-python-books.html?utm_source=rss&amp;utm_campaign=st-blog-feed</guid><pubDate>Tue, 31 Oct 2017 06:47:23 GMT</pubDate></item><item><title>Build a "function with a memory" in Python</title><link>https://www.samueltaylor.org/articles/function-with-memory.html?utm_source=rss&amp;utm_campaign=st-blog-feed</link><description>&lt;p&gt;Are you familiar with the &lt;code&gt;__call__&lt;/code&gt; method in Python? By defining this method, an instance of your class can be called
as though it were a function. Here's a contrived example solely to demonstrate how it works:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Foo&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;call_ct&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;initialized&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__call__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;call_ct&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;call_ct&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;bar&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Foo&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;bar&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;bar&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;baz&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Foo&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;baz&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;baz&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;bar&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Output:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;bar initialized
bar 1
baz initialized
baz 1
bar 2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A more interesting use case is &lt;a href="https://twitter.com/brandon_rhodes/status/923393090920026114"&gt;given by Brandon Rhodes&lt;/a&gt;,
that of swapping out an &lt;code&gt;http_get(url)&lt;/code&gt; method for an object that caches pages. Say for instance that we are maintaining
a project that includes the following web crawling code:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;urllib.request&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;urllib.error&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;HTTPError&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;URLError&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;http_get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;urllib&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;urlopen&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;page&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;page&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getcode&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;page&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;decode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;utf-8&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_links&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;page_content&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;loc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;page_content&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;href&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="n"&gt;loc&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;start&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;loc&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;href=&amp;quot;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;quote_char&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;page_content&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="n"&gt;end&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;page_content&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;quote_char&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;yield&lt;/span&gt; &lt;span class="n"&gt;page_content&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;end&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

        &lt;span class="n"&gt;loc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;page_content&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;href&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;loc&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;crawl&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;start_page&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;max_depth&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;on_page&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;stack&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;start_page&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="n"&gt;stack&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;depth&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;stack&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pop&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;code&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;content&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;http_get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="ne"&gt;ValueError&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;HTTPError&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;URLError&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="k"&gt;continue&lt;/span&gt;

        &lt;span class="n"&gt;on_page&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;code&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;content&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;depth&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;max_depth&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;code&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;stack&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extend&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;depth&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;u&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;u&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;get_links&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;content&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="vm"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;__main__&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;crawl&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;https://www.python.org&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;max_depth&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;on_page&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;code&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;content&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;code&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Now say we become unsatisfied with the performance of this code and want to stop getting the same page multiple times.
The standard library provides a &lt;a href="https://docs.python.org/3/library/functools.html?highlight=lru_cache#functools.lru_cache"&gt;caching
mechanism&lt;/a&gt; that we could
decorate our &lt;code&gt;http_get&lt;/code&gt; function with.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;functools&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;lru_cache&lt;/span&gt;

&lt;span class="c1"&gt;# ...&lt;/span&gt;

&lt;span class="nd"&gt;@lru_cache&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;http_get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;urllib&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;urlopen&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;page&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;page&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getcode&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;page&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;decode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;utf-8&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;But another option is an object that implements &lt;code&gt;__call__(self)&lt;/code&gt;. What might that look like?&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# ...&lt;/span&gt;
&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;CachedHttpGet&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cache&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{}&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__call__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;url&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cache&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;urllib&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;urlopen&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;page&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cache&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;page&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getcode&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;page&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;decode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;utf-8&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cache&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="n"&gt;http_get&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;CachedHttpGet&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="c1"&gt;# ...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;While &lt;code&gt;lru_cache&lt;/code&gt; is probably better in this contrived example, I hope this article gives you another tool for your
toolbox. The &lt;a href="https://docs.python.org/3/reference/datamodel.html#emulating-callable-objects"&gt;official docs are here&lt;/a&gt;.
Keep this in mind the next time you're refactoring something; it may be the right choice.&lt;/p&gt;</description><author>Samuel Taylor</author><guid isPermaLink="true">https://www.samueltaylor.org/articles/function-with-memory.html?utm_source=rss&amp;utm_campaign=st-blog-feed</guid><pubDate>Sat, 28 Oct 2017 11:32:48 GMT</pubDate></item><item><title>How to Attend a Tech Conference</title><link>https://www.samueltaylor.org/articles/how-to-attend-tech-conference.html?utm_source=rss&amp;utm_campaign=st-blog-feed</link><description>&lt;p&gt;Conferences can be both fun and valuable, but they can also be a huge waste of time. Here's some things I've learned
that have helped me get the most out of conferences as an attendee.&lt;/p&gt;
&lt;p&gt;(Prefer to listen? &lt;a href="/podcast.html"&gt;Subscribe to my podcast&lt;/a&gt;) for a narrated version.)&lt;/p&gt;
&lt;h2&gt;Consider skipping talks&lt;/h2&gt;
&lt;p&gt;This advice sounds crazy, I know; the whole point of conferences is to hear the speakers, right? I'm not convinced.  The
most valuable experiences I've had at conferences are centered around the people, not the talks.&lt;/p&gt;
&lt;p&gt;If sessions are recorded, you should go to very few sessions at all. Instead, ask people about what sessions they've
found particularly enlightening, then organize "lunch and learns" with your coworkers to watch those presentations.
While watching them, feel free to pause them and discuss. This discussion helps everyone involved more thoroughly
understand the material and how it may be applicable. Ironically, by skipping the talks, you often get more out of them.&lt;/p&gt;
&lt;h2&gt;Write in a pocket notebook&lt;/h2&gt;
&lt;p&gt;While I use my phone to keep track of lots of information, I find that at conferences nothing beats the simplicity of a
physical, paper notebook. The benefits are numerous. A notebook isn't going to flash a distracting notification on your
screen while you try to write down someone's email address or take notes on a talk. You'll look more put together and
less rude when writing something down on paper vs. on your phone. And I find that writing by hand forces my brain to be
more concise, a huge plus when you review these notes later.&lt;/p&gt;
&lt;p&gt;Aside from notes on any sessions you do end up attending, a notebook is also useful for keeping track of memorable
quotes, people's contact information, restaurant/activity recommendations, or (really) anything else.&lt;/p&gt;
&lt;p&gt;If you want to be trendy, lots of people like &lt;a href="https://fieldnotesbrand.com/products/original-kraft"&gt;Field Notes&lt;/a&gt;, but a
trip to your dollar store may yield something similarly valuable at a lower cost.&lt;/p&gt;
&lt;h2&gt;Create a followup plan&lt;/h2&gt;
&lt;p&gt;While pen and paper are excellent tools for capturing information, I have a different system for keeping track of my
todo list. Mine happens to be electronic and centered around Trello, but the ideas here can be applied to your personal
system.&lt;/p&gt;
&lt;p&gt;During the day, I gather a stack of business cards and contact information from interesting people. Then, when I have
spare time during/after the event, I take pictures of this information and add them all to a single "followup" card in
Trello. I make note of a relevant detail or two from each person as well. A few weeks later, I like to email these
people to follow up.&lt;/p&gt;
&lt;p&gt;If you don't have a plan, you're planning to fail.&lt;/p&gt;
&lt;h2&gt;Bring business cards&lt;/h2&gt;
&lt;p&gt;Handing someone a business card is often faster than writing down your email or having them type in your Twitter handle.
I prefer to use personal business cards (rather than those from my employer) because I want people to connect with &lt;em&gt;me&lt;/em&gt;,
not my company.&lt;/p&gt;
&lt;p&gt;I used &lt;a href="https://www.canva.com/"&gt;Canva&lt;/a&gt; to design and print my cards. Whoever you use, buy the smallest amount you can.
The per-unit price difference can make it tempting to buy 1000 cards, but you realistically aren't going to give out
1000 business cards before you become unsatisfied with some aspect of them. When you buy a smaller batch, you have the
freedom to change them more regularly. The relatively small per-unit cost increase is worth the added flexibility.&lt;/p&gt;
&lt;h2&gt;Track expenses on your phone, as they're happening&lt;/h2&gt;
&lt;p&gt;Keeping track of paper receipts is tedious compared to snapping a quick photo of your receipt. If your company
reimburses for travel/conference expenses, see if there's a mobile app for expense reports. By using it, you'll be less
likely to forget to expense something and you'll have less work to do when you get back from the conference.&lt;/p&gt;
&lt;h2&gt;Consider using Twitter&lt;/h2&gt;
&lt;p&gt;I usually avoid social media, but I created a Twitter account solely to connect with the people I was meeting at
conferences. It seems to be the preferred platform for many tech people, and it feels less stuffy than LinkedIn.&lt;/p&gt;
&lt;h2&gt;Use your calendar&lt;/h2&gt;
&lt;p&gt;Before the conference, look through the schedule and figure out which ones sound the most interesting. Put the name,
speaker's name, and location into your calendar. Even though you shouldn't be going to all of them, you can still enter
the most interesting talk in each time slot. By doing this, you should be able to avoid wasting time with schedules when
you could be talking to awesome people.&lt;/p&gt;
&lt;p&gt;As an aside, this has become one of my favorite use cases for my smart watch (a &lt;a href="https://www.amazon.com/Garmin-Forerunner-230-Black-White/dp/B016PAPI3W"&gt;Garmin
FR230&lt;/a&gt;). Knowing where you're headed without
having to pull out your phone is super convenient.&lt;/p&gt;</description><author>Samuel Taylor</author><guid isPermaLink="true">https://www.samueltaylor.org/articles/how-to-attend-tech-conference.html?utm_source=rss&amp;utm_campaign=st-blog-feed</guid><pubDate>Mon, 23 Oct 2017 18:33:01 GMT</pubDate></item><item><title>Speed up your Python-based web scraping</title><link>https://www.samueltaylor.org/articles/speed-up-web-scraping.html?utm_source=rss&amp;utm_campaign=st-blog-feed</link><description>&lt;p&gt;Sometimes when I'm working on a project that involves web scraping, the actual scraping starts to slow me down. If
you've ever re-run a script and then sat for a few minutes while your computer re-scraped the data, you know what I'm
talking about. I've found two simple and practical ways to make this process significantly faster.&lt;/p&gt;
&lt;p&gt;For the sake of example, say we're crawling two links deep on the front page of the New York Times. A straightforward
way of doing this is:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import requests
from bs4 import BeautifulSoup

def get_links(url):
    r = requests.get(url)
    soup = BeautifulSoup(r.text, 'lxml')
    return {e.get('href') for e in soup.find_all('a')
            if e.get('href') and e.get('href').startswith('https')}

links = get_links('https://www.nytimes.com')

all_links = set()
for link in links:
    all_links |= get_links(link)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;On my machine/internet, this took about 103 seconds. We can do better than that!&lt;/p&gt;
&lt;h2&gt;Use &lt;code&gt;multiprocessing&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;Python's &lt;code&gt;multiprocessing&lt;/code&gt; module can help speed up I/O-bound tasks like web scraping. Our case here is a good example
because we don't need to scrape each link separately; we can run them in parallel. The first step here is to convert our
code to use the built in &lt;code&gt;map&lt;/code&gt; function:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import itertools as it
# import requests
# ...
# links = get_links('https://www.nytimes.com')

links_on_pages = map(get_links, links)
all_links = set(it.chain.from_iterable(links_on_pages))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;On my machine, this ran in a similar amount of time to the original example. From there, using &lt;code&gt;multiprocessing&lt;/code&gt; is a
quick change:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import multiprocessing
# import itertols as it
# ...
# links = get_links('https://www.nytimes.com')

with multiprocessing.Pool() as p:
    links_on_pages = p.map(get_links, links)
# all_links = ...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This example ran in about 25 seconds (~24% of the original time). The speed-up happens because Python spins up four
worker processes[0] that go through &lt;code&gt;links&lt;/code&gt; and run &lt;code&gt;get_links&lt;/code&gt; on each element. You can tweak the number of processes
that are spawned to get even faster wall-clock times. For example, by using 8 worker processes, the script took 16
seconds instead of 25.  This won't scale infinitely, but it can be a simple and effective way to speed things up in
cases where your code doesn't have to be entirely serial.&lt;/p&gt;
&lt;h2&gt;Cache to disk&lt;/h2&gt;
&lt;p&gt;One common use case I have for scraped data is to analyze it in a Jupyter notebook. I have a habit of using the "Restart
kernel and run all" option to re-run my whole notebook, but that means the scraping has to run again. I often don't want
to wait a few minutes for my computer to do something it already did 10 minutes ago. In cases like this, I've found
caching the results of my scraping to disk to be a useful way to avoid re-doing work.&lt;/p&gt;
&lt;p&gt;As a first step, let's move our existing code into a function:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;def get_links_2_deep(url):
    links = get_links(url)
    with multiprocessing.Pool(8) as p:
        links_on_pages = p.map(get_links, links)
    return set(it.chain.from_iterable(links_on_pages))

print(len(get_links_2_deep('https://www.nytimes.com')))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can extend our code to cache the result of this function to disk by writing a decorator.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;def cache_to_disk(func):
    def wrapper(*args):
        cache = '.{}{}.pkl'.format(func.__name__, args).replace('/', '_')
        try:
            with open(cache, 'rb') as f:
                return pickle.load(f)
        except IOError:
            result = func(*args)
            with open(cache, 'wb') as f:
                pickle.dump(result, f)
            return result

    return wrapper
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let's use the decorator:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@cache_to_disk
def get_links_2_deep(url):
#    links = ...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After the first time we run this script, it's able to load the cached result, which takes around a quarter of a second.
I find this useful while I'm writing and developing some analysis code, but I have to be mindful that to get the most
up-to-date results, I need to delete the &lt;code&gt;.pkl&lt;/code&gt; file that this is using as its cache. I happily take this tradeoff, and
if this technique fits your use case, you should too!&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;0: I say four here because my computer has four cores. When no arguments are passed to the &lt;code&gt;Pool()&lt;/code&gt; constructor, Python
chooses the amount of processes in the pool to be the result of &lt;code&gt;os.cpu_count()&lt;/code&gt;
(&lt;a href="https://docs.python.org/3/library/multiprocessing.html#multiprocessing.pool.Pool"&gt;docs&lt;/a&gt;).&lt;/p&gt;</description><author>Samuel Taylor</author><guid isPermaLink="true">https://www.samueltaylor.org/articles/speed-up-web-scraping.html?utm_source=rss&amp;utm_campaign=st-blog-feed</guid><pubDate>Sun, 07 May 2017 17:32:17 GMT</pubDate></item><item><title>Income inequality in professional sports</title><link>https://www.samueltaylor.org/articles/sport-salary-inequality.html?utm_source=rss&amp;utm_campaign=st-blog-feed</link><description>&lt;p&gt;On his podcast &lt;a href="http://revisionisthistory.com/"&gt;Revisionist History&lt;/a&gt;, Malcolm Gladwell talks about the difference
between "weak link" and "strong link" sports. A "weak link" sport is one in which the worst player's skill level has a
large impact on the team's success. The example Gladwell gives is soccer, in which a long chain of events must go
perfectly to score a point. To get the ball from one side of the field to a position in which a team can make a
successful shot on goal requires a lot of dribbling and passing. Every time the ball is passed is an opportunity for the
opposing team to break the chain, requiring the attacking team to start the chain from the beginning.&lt;/p&gt;
&lt;p&gt;By contrast, basketball is a "strong link" sport [0]. In such a sport, the best player's skill level (rather than the
worst) has a large impact on the team's success. A superstar in basketball can take a team to the playoffs almost
entirely on his own.&lt;/p&gt;
&lt;p&gt;If this "strong link"/"weak link" hypothesis is true and players are compensated proportionally to their contribution to
the team's overall success[1], I would expect income inequality to be greater in basketball than in soccer. At this
point, I went looking for data.&lt;/p&gt;
&lt;p&gt;After some searching, I found &lt;a href="http://www.spotrac.com/"&gt;Spotrac&lt;/a&gt;, which has salary data for the NFL, NBA, MLB, NHL, and
MLS. After scraping the site, I had a decent dataset of salaries. First, I looked at a histogram of the salaries:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(16, 10))
axes[1, 2].set_visible(False)

for ndx, league in enumerate(df['League'].unique()):
    league_df = df[df.League == league]
        league_df.plot(kind='hist', ax=axes[ndx % 2, ndx % 3], title='{} salary distribution ({} players)'.format(league, league_df.shape[0]))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="/static/img/salary_dist.png" alt="Professional sport league salary distribution"&gt;&lt;/img&gt;&lt;/p&gt;
&lt;p&gt;Standard deviation quantifies the variation in the distribution, but comparing the standard deviations across leagues
doesn't make sense because the mean salary in each league is so different. By dividing the standard deviation by the
mean, we get the &lt;a href="https://en.wikipedia.org/wiki/Coefficient_of_variation"&gt;coefficient of variation&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;aggregates = df.groupby('League').agg([len, np.mean, np.std, np.median])['Base Salary']
cv = (aggregates['std'] / aggregates['mean'])
cv.sort_values().plot(kind='bar', title='std as percent of mean')
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="/static/img/salary_std_over_mean.png" alt="Professional sport league salary standard deviation over mean"&gt;&lt;/img&gt;&lt;/p&gt;
&lt;p&gt;This tells us that MLS salaries vary most widely and NHL salaries vary the least. Digging deeper into the MLS, Bastian
Schweinsteiger is making $5,400,000 in base salary, with the next highest salary being Tim Howard's $2,000,000. Removing
just Schweinsteiger would leave the MLS with a CV of around 1.26, which is higher than the NBA's, but lower than the
MLB's.&lt;/p&gt;
&lt;p&gt;What have we learned? In terms of income inequality in the American professional sports leagues, soccer actually has the
most income inequality, and the NBA has the second-to-least. I think the reason that my initial hypothesis is incorrect
is twofold: (1) player contribution to team success is not the only factor in compensation and (2) teams don't
universally believe that basketball and soccer are strong and weak link sports (respectively).&lt;/p&gt;
&lt;p&gt;I would be curious to see how these results change if we're looking solely at starters (rather than entire rosters), but
that'll have to be another question for another day.&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;0: Daniel Forsyth provides an interesting &lt;a href="http://www.danielforsyth.me/is-basketball-a-weakest-link-sport/"&gt;analysis of this
claim&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;1: They aren't, at least, they aren't solely compensated according to this factor. The team owner also gets value out of
selling jerseys and other merchandise, which is easier to do for more famous players.&lt;/p&gt;</description><author>Samuel Taylor</author><guid isPermaLink="true">https://www.samueltaylor.org/articles/sport-salary-inequality.html?utm_source=rss&amp;utm_campaign=st-blog-feed</guid><pubDate>Sun, 30 Apr 2017 17:03:47 GMT</pubDate></item><item><title>Host all your projects on one machine with Docker</title><link>https://www.samueltaylor.org/articles/docker-for-projects.html?utm_source=rss&amp;utm_campaign=st-blog-feed</link><description>&lt;p&gt;Like many digital builders/hackers/makers, I have &lt;a href="../projects/index.html"&gt;several
projects&lt;/a&gt; that I want to put on the internet. I don't,
however, want to have loads of servers to manage. Given that the highest-traffic
project I maintain only around 100 unique visitors a day, it's feasible for me
to host them all on the same node.&lt;/p&gt;
&lt;p&gt;I already deploy these things in Docker containers, so I imagined I could use
nginx to solve this problem. It would work, I imagined, by having a single
Docker host running an nginx container that would reverse proxy requests to
other containers (which would be running the aforementioned projects). When I
started researching how to do this, I found a great project that made it super
easy.&lt;/p&gt;
&lt;p&gt;Jason Wilder has a &lt;a href="http://jasonwilder.com/blog/2014/03/25/automated-nginx-reverse-proxy-for-docker/"&gt;great
post&lt;/a&gt;
that you should read if you want more detail, but the gist is that
&lt;a href="https://hub.docker.com/r/jwilder/nginx-proxy/"&gt;jwilder/nginx-proxy&lt;/a&gt; is an nginx
container that proxies to other containers. It automatically configures nginx
based on the &lt;code&gt;EXPOSE&lt;/code&gt;d ports of the containers you're running, which is almost
magical.&lt;/p&gt;
&lt;p&gt;Start it up like this:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;docker run -d -p 80:80 -v /var/run/docker.sock:/tmp/docker.sock -t jwilder/nginx-proxy&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;You can make this even cooler with a bit of fiddling with your DNS records. Add
an A record that points to the Docker host, then add a wildcard CNAME that
points to the URL you set up in the A record (see screenshot below for how I
have it set up).&lt;/p&gt;
&lt;p&gt;&lt;img src="/static/img/dns_config.png" alt="DNS configuration"&gt;&lt;/img&gt;&lt;/p&gt;
&lt;p&gt;(where "1.2.3.4" is the IP of your Docker host)&lt;/p&gt;
&lt;p&gt;Now, you can start up a container with a &lt;code&gt;VIRTUAL_HOST&lt;/code&gt; environment variable
that is in that subdomain:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;docker run -e 'VIRTUAL_HOST=rss.project.samueltaylor.org' -tid ssaamm/rss_filter&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;When you navigate to this URL, your browser will ask your nginx container for
the site at that URL, and that container will know to reverse proxy the request
to the container you just started. Nifty!&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;Please reach out if you have any questions or want to get in touch! My email
address is sgt at this domain.&lt;/p&gt;</description><author>Samuel Taylor</author><guid isPermaLink="true">https://www.samueltaylor.org/articles/docker-for-projects.html?utm_source=rss&amp;utm_campaign=st-blog-feed</guid><pubDate>Sat, 18 Feb 2017 08:07:29 GMT</pubDate></item><item><title>The Last 5 Books I Read (as of March 2017)</title><link>https://www.samueltaylor.org/articles/books-mar17.html?utm_source=rss&amp;utm_campaign=st-blog-feed</link><description>&lt;h2&gt;The Braindead Megaphone, George Saunders&lt;/h2&gt;
&lt;p&gt;This collection of nonfiction essays was enjoyable and thought-provoking.
Saunders writes about the Iraq war, illegal immigration, and Dubai. He presents
his experiences in a very relatable way.&lt;/p&gt;
&lt;h2&gt;The Crying of Lot 49, Thomas Pynchon&lt;/h2&gt;
&lt;p&gt;I didn't like this one. I put it down about halfway through; I just couldn't get
into it. I didn't find anything about it intriguing in the slightest.&lt;/p&gt;</description><author>Samuel Taylor</author><guid isPermaLink="true">https://www.samueltaylor.org/articles/books-mar17.html?utm_source=rss&amp;utm_campaign=st-blog-feed</guid><pubDate>Tue, 10 Jan 2017 17:31:12 GMT</pubDate></item><item><title>Wherever you are, be all there</title><link>https://www.samueltaylor.org/articles/be-all-there.html?utm_source=rss&amp;utm_campaign=st-blog-feed</link><description>&lt;p&gt;Being present (paying attention to the here and now) and purposeful (taking
actions to achieve some end) helps us to live more fulfilling lives. Jim Elliot
once said, "wherever you are, be all there." While it is often painted on
flowery backdrops and put on the walls of suburban homes, this quote holds
useful advice for productivity and professional growth.&lt;/p&gt;
&lt;p&gt;If you're doing something, you should apply all your efforts to that thing, and
avoid distractions or other tasks. Turn off your phone, close your chat program,
and just work. When your brain encounters a difficult task like learning a new
skill or solving a challenging problem, it tries to avoid spending the energy on
that hard thing. Instead, you'll suddenly feel the urge to check your text
messages or open up Twitter.  Your brain might start reminding you about the
fact that you need to schedule a doctor's appointment or get your car washed.
You've got to fight these urges, or you'll get derailed from the task at hand
and become less productive. You will be more productive if you focus on and
complete your current task and then apply all your focus to (for instance)
scheduling a doctor's appointment than you would if you try to do both at once.
To help avoid your brain's weakling pleas for relief from the mental workout,
many people find it useful to set a timer for a set period of working on a
specific task (see for example &lt;a href="https://en.wikipedia.org/wiki/Pomodoro_Technique"&gt;the Pomodoro
technique&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;This quote is also great career development advice. Wherever you find yourself
professionally, you should use the resources at your disposal to your maximum
advantage. Find the truly great people at your company and try to learn from
them. Take them to coffee and ask them how they are so effective. Ask them to
critique your work. Over the course of your daily interactions, observe how
they handle situations you would be uncomfortable in. Beyond the people at your
company, try to get yourself assigned to projects that stretch your abilities.&lt;/p&gt;
&lt;p&gt;Life is more rewarding when we live purposefully in the present. By focusing on
one task at a time and making the most of our resources, we can become better
people and find more fulfillment.&lt;/p&gt;</description><author>Samuel Taylor</author><guid isPermaLink="true">https://www.samueltaylor.org/articles/be-all-there.html?utm_source=rss&amp;utm_campaign=st-blog-feed</guid><pubDate>Sun, 13 Nov 2016 15:45:23 GMT</pubDate></item><item><title>Experiments with Self-Tracking/Quantified Self</title><link>https://www.samueltaylor.org/articles/quantified-self.html?utm_source=rss&amp;utm_campaign=st-blog-feed</link><description>&lt;h2&gt;How many times in a row do I typically sneeze?&lt;/h2&gt;
&lt;p&gt;Ever since I can remember, I've sneezed atypically. While most people sneeze
once and are done, I often sneeze 3, 4, or even 8 times in a row. I was curious
to see how often I sneeze a certain number of times in a row, so I kept track of
every time I sneezed over the course of a week. Here are the results:&lt;/p&gt;
&lt;p&gt;&lt;img src="/static/img/quantified_self_sneeze_histogram.png" alt="Sneeze histogram"&gt;&lt;/img&gt;&lt;/p&gt;
&lt;p&gt;All this time, I though it was fairly rare for me to sneeze once. In reality, I
sneeze once in a row with decent frequency, and I sneeze twice very
infrequently.&lt;/p&gt;
&lt;h2&gt;How long does it take to get to work?&lt;/h2&gt;
&lt;p&gt;For a little while, I tracked my commute time with a DO Button that logged the
time and my location to a spreadsheet. After &lt;a href="https://github.com/ssaamm/personal-etl/blob/d96b546f62cb36f865b938acef5de71e069499dc/commute_time.py"&gt;a little cleaning&lt;/a&gt;,
the data looks like this:&lt;/p&gt;
&lt;div id="commute-time"&gt;&lt;/div&gt;

&lt;script&gt;
  d3.csv('../static/data/commute_time.csv', function(data) {
    MG.data_graphic({
      data: data.map(function transform(point) {
        return {
          'start_time': new Date(point.start_time),
          'duration': point.duration / 60,
          'destination': point.destination == 'WORK' ? 'Work' :
            point.destination == 'HOME' ? 'Home' : 'Unknown',
        };
      }),
      //full_width: true,
      //height: 400,
      //right: 40,
      chart_type: 'point',
      target: '#commute-time',
      x_accessor: 'start_time',
      y_accessor: 'duration',
      y_label: 'Duration (min)',
      color_accessor: 'destination',
      color_type: 'category',
      area: false,
      interpolate: 'linear',
    });
  });
&lt;/script&gt;</description><author>Samuel Taylor</author><guid isPermaLink="true">https://www.samueltaylor.org/articles/quantified-self.html?utm_source=rss&amp;utm_campaign=st-blog-feed</guid><pubDate>Tue, 08 Nov 2016 11:35:48 GMT</pubDate></item><item><title>Writing Better Code: Code as Communication</title><link>https://www.samueltaylor.org/articles/better-code-code-as-communication.html?utm_source=rss&amp;utm_campaign=st-blog-feed</link><description>&lt;p&gt;After we compile our code, why do we keep it? The machine is able to interpret
the compiled code and perform the function we wanted it to, so why keep the
original code around? Often, the answer to this question is that we may need to
modify the program in the future. Modifying a bunch of 1's and 0's in a compiled
file would be very costly in terms of developer time. We keep the original code
because we can maintain it more easily than the compiled code.&lt;/p&gt;
&lt;p&gt;Code is read more often than it is written. As such, when we are writing code,
we should keep future developers in mind. Our code is a tool for communicating
with future developers who are attempting to maintain it. I find two worthwhile
ways to make code more communicative.&lt;/p&gt;
&lt;h2&gt;Avoid unnecessary comments&lt;/h2&gt;
&lt;p&gt;Only write comments that explain something which isn't apparent after reading
the code.&lt;/p&gt;
&lt;p&gt;As an example, suppose we're writing an application that interacts with a web
API to get the current weather. We might write something like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;r = requests.get('http://weather.example.com/currentweather?zip=76706')
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A bad comment for this code might look like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# make a GET request to the weather API for a given ZIP code
r = requests.get('http://weather.example.com/currentweather?zip=76706')
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This comment is unnecessary because it's more or less restating what the code
says. Any developer reading this code sans the comment will be able to surmise
that it makes a GET request to some weather API for some ZIP code. Because
developers can figure this out without the comment, the comment is unnecessary.&lt;/p&gt;
&lt;p&gt;Unnecessary comments are unnecessary; who would've guessed? More interestingly,
I would argue that they can be harmful. In the future, the API and our use of it
may change in a number of ways. Suppose we want to lookup weather with a
latitude/longitude coordinate or that the developers of the API require us to
make a POST request. We open our code back up, find the line where we look up
the weather, and modify it&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# make a GET request to the weather API for a given ZIP code
r = requests.post('http://weather.example.com/currentweather?lat=31.5491667&amp;amp;lon=-97.1463889')
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Oops! In our haste to update our code, we forgot to update the comment above it,
which is now an incorrect description of the code below it. Our program
continues to work just fine (the compiler or interpreter doesn't care about the
comments), but we've left a confusing artifact for the next developer to find.
Unnecessary comments are harmful because they can become out of sync with the
code they are describing, creating confusion and slowing down developers.&lt;/p&gt;
&lt;p&gt;A better comment might look like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# get current weather in Waco
r = requests.get('http://weather.example.com/currentweather?zip=76706')
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This comment is better because it's speaking to the reasoning for the code below
it. As a rule of thumb, comments should describe the &lt;em&gt;why&lt;/em&gt; rather than the
&lt;em&gt;what&lt;/em&gt;. Because this comment describes the &lt;em&gt;why&lt;/em&gt; rather than the &lt;em&gt;what&lt;/em&gt;, it is
still true when we modify our code as we did abobe--we're still getting the
current weather in Waco.&lt;/p&gt;
&lt;p&gt;Still, I don't love this comment. It's probably unnecessary, as a developer can
probably figure out that we're getting the weather (though they may not know
Waco's ZIP code). At the same time, we may not want future developers to
have to take the time to read this code thoroughly; that's wy we wrote a comment
in the first place! If our intent is to create a program that is easily read and
understood, I think there are often better tools than comments.&lt;/p&gt;
&lt;h2&gt;Write self-documenting code&lt;/h2&gt;
&lt;p&gt;Name and create the constructs of your programs in such a way as to be easily
read and understood by future maintainers.&lt;/p&gt;
&lt;p&gt;In our previous example, we were getting the current weather in a given place.
Because we didn't want a future developer to have to read our code in order to
understand it, we wrote a comment explaining what it did. Alternatively, we
could have created a well-named function:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;def get_current_weather(zip_code):
    return requests.get(f'http://weather.example.com/currentweather?zip={zip_code}')
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Using this function might look like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;get_current_weather(zip_code=76706)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Because the function's behavior is easy to infer from its name, maintainers
don't have to read the definition of &lt;code&gt;get_current_weather&lt;/code&gt; to understand what it
does (though they can easily choose to). Further, changes to the function can be
enforced by the interpreter. Suppose we modify this function to take a
latitude/longitude coordinate:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;def get_current_weather(lat, lon):
    return requests.get(f'http://weather.example.com/currentweather?lat={lat}&amp;amp;lon={lon}')
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, if we try to run our program without updating our calls to that function,
the interpreter will tell us:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;TypeError: get_current_weather() got an unexpected keyword argument 'zip_code'
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;By creating a well-named function, we not only improved our program's
readability, we also made it harder for maintainers to break our program
unintentionally.&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;You should be thoughtful about the code you write because the marginal cost of
being a bit more thoughtful on writing the code is less than the cost of the
additional time future developers will have to spend in order to read your code.&lt;/p&gt;</description><author>Samuel Taylor</author><guid isPermaLink="true">https://www.samueltaylor.org/articles/better-code-code-as-communication.html?utm_source=rss&amp;utm_campaign=st-blog-feed</guid><pubDate>Sat, 29 Oct 2016 10:17:05 GMT</pubDate></item><item><title>k-Nearest Neighbors</title><link>https://www.samueltaylor.org/articles/2016-10-18_knn.html?utm_source=rss&amp;utm_campaign=st-blog-feed</link><description>&lt;p&gt;On 18 Oct 2016, I gave a talk at Austin ACM SIGKDD on the &lt;em&gt;k&lt;/em&gt;-nearest neighbors
algorithm. Topics included some machine learning theory (approximation vs.
generalization, VC dimension), the algorithm itself, proving the algorithm's
performance, and some practical concerns around choosing &lt;em&gt;k&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Some other topics that I would probably include next time are similarity
functions, high-dimensional spaces, and categorical data.&lt;/p&gt;
&lt;p&gt;You can find the slides &lt;a href="/static/pdf/2016-10-18_knn.pdf"&gt;here&lt;/a&gt;. Note that my
presentation probably won't make a ton of sense from these slides, as they were
mostly aids to the words I was saying out loud. If you've got any questions,
feel free to email me; I'd love to chat!&lt;/p&gt;
&lt;p&gt;Thanks to everyone who came to watch; I appreciated hearing your feedback!&lt;/p&gt;</description><author>Samuel Taylor</author><guid isPermaLink="true">https://www.samueltaylor.org/articles/2016-10-18_knn.html?utm_source=rss&amp;utm_campaign=st-blog-feed</guid><pubDate>Thu, 27 Oct 2016 08:29:58 GMT</pubDate></item><item><title>Python Puzzlers</title><link>https://www.samueltaylor.org/articles/python-puzzlers.html?utm_source=rss&amp;utm_campaign=st-blog-feed</link><description>&lt;h2&gt;Default arguments&lt;/h2&gt;
&lt;p&gt;What is the output of this code?&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;def foo(arg=[]):
    return arg

my_list = foo()
my_list.extend('abc')

print(foo())
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;My first intution was that this would output the empty list (&lt;code&gt;[]&lt;/code&gt;). However, the
output is:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;['a', 'b', 'c']
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Why does this happen? Well, Python evaluates default arguments when the function
is defined, rather than when it's run. As a consequence, if a default argument
is mutable and is mutated in one function call, future function calls will be
working with the mutated argument.&lt;/p&gt;
&lt;h3&gt;Check your understanding&lt;/h3&gt;
&lt;p&gt;Now that you know a bit more about default arguments, what is the output of this
code?&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;def bar(arg=[]):
    arg.append('a')
    return arg

bar()
print(bar())
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you answered:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;['a', 'a']
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;then you're right!&lt;/p&gt;</description><author>Samuel Taylor</author><guid isPermaLink="true">https://www.samueltaylor.org/articles/python-puzzlers.html?utm_source=rss&amp;utm_campaign=st-blog-feed</guid><pubDate>Wed, 28 Sep 2016 19:32:46 GMT</pubDate></item><item><title>The Last 5 Books I Read (October 2016)</title><link>https://www.samueltaylor.org/articles/books-october16.html?utm_source=rss&amp;utm_campaign=st-blog-feed</link><description>&lt;h2&gt;Station Eleven, Emily St. John Mandel&lt;/h2&gt;
&lt;p&gt;I picked up this book purely for entertainment, and it served that purpose well.
The pacing is quick (at times excessively so), and the events are interesting. I
found nothing about it revolutionary, but it was well-written. In particular, I
liked the dialogue because it felt real (perhaps accentuated by the fact that I
read the book aloud).&lt;/p&gt;
&lt;p&gt;As events unfold in a few different timeframes, we see some characters and
events in a new light. While many of these unveilings worked well, they
sometimes felt like they were explaining too much, taking away some of the fun
of piecing together the story. Following these threads of story through various
timeframes is fun, but feels pointless sometimes. For instance, the author
traces a paperweight's journey which I didn't find engaging.&lt;/p&gt;
&lt;p&gt;The characterization left something to be desired. Only once did I feel like I
understood a character at a non-surface level (the description of Miranda's
thoughts on clothes being "armor" gives insight into her post-divorce
life/feelings). Still, while I didn't end up caring very much about any of the
characters in particular, I kept reading because the story was interesting.&lt;/p&gt;
&lt;p&gt;This book seems like one that many will like, but few will choose as their
favorite. That's completely fine; not every book can be a total masterpiece. Go
into it looking to be entertained, and you probably will be.&lt;/p&gt;
&lt;h2&gt;So Good They Can't Ignore You, Cal Newport&lt;/h2&gt;
&lt;p&gt;I loved &lt;em&gt;Deep Work&lt;/em&gt;, so I decided to read this one, too. The book is about
creating a fulfilling career, which seems appropriate for a new college grad.
His premise seems solid to me--"follow your passion" is terrible advice. I
appreciate the cynicism of lifestyle bloggers (it seems the only ones making a
living are the ones selling lifestyle blogging to people who hate their jobs).&lt;/p&gt;
&lt;p&gt;Newport tells the stories of several individuals well. Like all self-help books,
these stories keep the book moving while demonstrating a point relevant to the
larger topic.&lt;/p&gt;
&lt;p&gt;My least favorite part of the book was that the author sometimes comes off as
overly cocky, which is annoying at best.&lt;/p&gt;
&lt;p&gt;Like lots of books in this genre, it got a little repetitive; he summarizes
himself over and over again.&lt;/p&gt;
&lt;p&gt;Aside from these two criticisms, though, I really liked the book. I seem to have
lucked out in that I'm fascinated with computer science/software development,
and the market seems to also like it. Still, the career advice seems well
thought out and will be useful in the coming years.&lt;/p&gt;
&lt;h2&gt;You Can't Win, Jack Black&lt;/h2&gt;
&lt;p&gt;Originally published as a series of newspaper articles, this book is the
autobiography of a rail riding, jewel thieving hobo in the late 19th and early
20th century named Jack Black. He recounts many tales including prison
sentences, hobo rituals, and his most interesting crimes. The glimpse Black
offers into a very specific subculture is fascinating. If you're interested in
reading a collection of true, interesting tales about a life on the road,
consider picking this book up.&lt;/p&gt;
&lt;h2&gt;Pastoralia, George Saunders&lt;/h2&gt;
&lt;p&gt;This collection of short stories enjoys giving its readers a look into the
internal monologues of its characters. The titular story was gripping, forcing
its reader to piece together the world from hints in the text.&lt;/p&gt;
&lt;p&gt;While the book is a collection of short stories, they are all drawn from the
same universe--an exaggerated version of America. I recently finished
watching the series &lt;em&gt;Black Mirror&lt;/em&gt;, and reading this book reminded me a bit of
that series. Though there's less technology in this book, it still feels like
the author is using a somewhat imagined world to critique our real one.&lt;/p&gt;
&lt;h2&gt;Slaughterhouse-Five, George Saunders&lt;/h2&gt;
&lt;p&gt;This book is a unique blend of science fiction and World War 2 tale. Its central
character, Billy Pilgrim, is cast about in many ways by the war. Perhaps
uncoincidentally, he sort of trips through time, which makes for an interesting
literary device.&lt;/p&gt;
&lt;p&gt;This book leaves me feeling very bleak. Pilgrim adopts the belief that
everything that will happen will happen, is happening, and has always been
happening; we are like bugs trapped in the amber of this moment. This belief
takes away hope and meaning. Without these two things, I'm not sure life is
worth living.&lt;/p&gt;</description><author>Samuel Taylor</author><guid isPermaLink="true">https://www.samueltaylor.org/articles/books-october16.html?utm_source=rss&amp;utm_campaign=st-blog-feed</guid><pubDate>Mon, 05 Sep 2016 19:07:40 GMT</pubDate></item><item><title>Quotes/thoughts that I like</title><link>https://www.samueltaylor.org/articles/important-quotes.html?utm_source=rss&amp;utm_campaign=st-blog-feed</link><description>&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;There are four hard things in life. If you can do these four things, the rest
  comes easy:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Working hard&lt;/li&gt;
&lt;li&gt;Doing your best&lt;/li&gt;
&lt;li&gt;Telling the truth&lt;/li&gt;
&lt;li&gt;Taking responsibility for your actions&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;My brothers and sisters, whenever you face trials of any kind, consider it
  nothing but joy, because you know that the testing of your faith produces
  endurance; and let endurance have its full effect, so that you may be mature
  and complete, lacking in nothing. (James 1:2-4, NRSV)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The poison from which the weaker nature perishes strengthens the strong
  man–and he does not call it poison (Friedrich Nietzsche, &lt;em&gt;The Gay Science&lt;/em&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Perfection is achieved not when there is nothing more to add, but when there
  is nothing left to take away. (Antoine de Saint-Exupery)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Note: the attributions on these are only a best guess&lt;/em&gt;&lt;/p&gt;</description><author>Samuel Taylor</author><guid isPermaLink="true">https://www.samueltaylor.org/articles/important-quotes.html?utm_source=rss&amp;utm_campaign=st-blog-feed</guid><pubDate>Mon, 29 Aug 2016 18:52:25 GMT</pubDate></item><item><title>Books I read in June 2015</title><link>https://www.samueltaylor.org/articles/books-june15.html?utm_source=rss&amp;utm_campaign=st-blog-feed</link><description>&lt;p&gt;This month, I read four books:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Till We Have Faces, C.S. Lewis&lt;/li&gt;
&lt;li&gt;A Walk in the Woods, Bill Bryson&lt;/li&gt;
&lt;li&gt;Of Mice and Men, John Steinbeck&lt;/li&gt;
&lt;li&gt;Into the Wild, Jon Krakauer&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Till We Have Faces, C.S. Lewis&lt;/h2&gt;
&lt;p&gt;I really enjoyed this one. It is a re-telling by Lewis of myth of Psyche and
Cupid. I was unfamiliar with the original myth, but appreciated this book very
much.&lt;/p&gt;
&lt;p&gt;I particularly enjoyed the clash in worldviews between a physically-oriented
worldview and one which stressed the importance of supernatural beings. The
differing advice offered to Orual by the Fox and the captain of the king's guard
is intriguing. The relationship between reason and faith is interesting, so I
enjoyed watching Orual process her thoughts on the world through the book.&lt;/p&gt;
&lt;p&gt;The book also stands out as a well-written story. I enjoyed the pace of it, and
I would highly recommend it to anyone who enjoys mythology.&lt;/p&gt;
&lt;h2&gt;A Walk in the Woods, Bill Bryson&lt;/h2&gt;
&lt;p&gt;This was a good read. Every once in a while, I would start to get a little bored
by the writing about the history or biology of the Appalachian Trail, but then
Bryson would say something to the effect of, "Enough science for now, back to
the interesting stuff."&lt;/p&gt;
&lt;p&gt;I enjoyed the interactions between Bryson, Katz, and others they ran into on the
trail.&lt;/p&gt;
&lt;p&gt;On an unrelated note, as of writing, Scott Jurek was about to break the FKT for
the AT. Jurek is an impressive athlete, and it's awesome to see such a huge
accomplishment.&lt;/p&gt;
&lt;h2&gt;Of Mice and Men, John Steinbeck&lt;/h2&gt;
&lt;p&gt;Quick read -- I think it took me an afternoon. I hadn't been spoiled for it, so
I didn't know what was coming. This book was very sad, but in an enjoyable way.
In a way, the ending sort of snuck up on me. I was observing the world Steinbeck
set before me, and then suddenly the ending came. It felt abrupt, and it felt
sad.&lt;/p&gt;
&lt;h2&gt;Into the Wild, Jon Krakauer&lt;/h2&gt;
&lt;p&gt;While I wasn't a fan of how much Krakauer seemed to revere McCandless, I enjoyed
hearing about McCandless's journey.&lt;/p&gt;</description><author>Samuel Taylor</author><guid isPermaLink="true">https://www.samueltaylor.org/articles/books-june15.html?utm_source=rss&amp;utm_campaign=st-blog-feed</guid><pubDate>Sun, 26 Jun 2016 11:04:55 GMT</pubDate></item><item><title>The Last 5 Books I Read (June 2016)</title><link>https://www.samueltaylor.org/articles/books-june16.html?utm_source=rss&amp;utm_campaign=st-blog-feed</link><description>&lt;h2&gt;A View from the Bridge, Arthur Miller&lt;/h2&gt;
&lt;p&gt;This is a script I read for my American Literature class. It was alright. Even
though it has a distant setting, the characters still feel real. They each have
their own needs/desires which conflict in certain ways, which causes the
drama/action. My favorite scene is one in which they're all in the apartment,
and Catherine and Rodolfo start dancing. The subtext in that scene is very
interesting.&lt;/p&gt;
&lt;p&gt;People talk about the ending being shocking, and I don't know that I agree.
There's enough foreshadowing and character development that it isn't a surprise.&lt;/p&gt;
&lt;p&gt;Anyway, it's a fine script. I imagine it's better as an actual staged
performance, and I would probably go see it if I knew it was being performed.&lt;/p&gt;
&lt;h2&gt;Questions for All your Answers, Roger E. Olson&lt;/h2&gt;
&lt;p&gt;This would have been a good book to give a 13 year old version of myself. At
that time, I was struggling with how anti-intellectual the church seemed.
Fortunately, for a few reasons I came to find and appreciate the intellectual
tradition of Christianity. As such, I don't think I'm necessarily the target
audience for the book. Reading it is still enjoyable, but it's not
earth-shattering for me.&lt;/p&gt;
&lt;p&gt;More generally, Olson seems to be caught in the awkward task of speaking
intellectually and theologically to an audience hostile (or apathetic, at best)
toward theological thinking. His writing feels at times pulled in different
direction. In one corner, he's trying to explain complicated theological lines
of thought. In another corner, he's trying to keep it simple enough that people
without much theological background can understand it.&lt;/p&gt;
&lt;p&gt;That said, there are still parts of the book that I liked. The third chapter was
particularly good; it talks about cultural sensitivity and the Trinity in a very
practical way that still respects the ideas.&lt;/p&gt;
&lt;h2&gt;Room, Emma Donoghue&lt;/h2&gt;
&lt;p&gt;I watched the movie adaptation on a plane and enjoyed it thoroughly. The book is
written from the perspective of a child, which seems like an annoying premise.
At times the perspective is a bit annoying, but overall I was surprised by how
well it worked.&lt;/p&gt;
&lt;p&gt;All in all, I enjoyed it a good deal. Because of the narrator's limited
knowledge, I was constantly intrigued and kept reading to find out more. While I
didn't, you could probably read it in one sitting as it's relatively short.&lt;/p&gt;
&lt;h2&gt;Ready Player One, Ernest Cline&lt;/h2&gt;
&lt;p&gt;I didn't like the main character at the beginning of the book, which was not
enjoyable. I suppose you could argue that this is Cline setting up for some
character development, but that isn't a satisfying answer. Ideally, there would
be a way to establish that the character is hauty without making readers hate
him. Luckily, Parzival/Wade became a more interesting, less prideful character
as I got further in the book.&lt;/p&gt;
&lt;p&gt;At times, something would happen in the book that felt irrelevant enough to the
plot that I would be drawn out of the action and start wondering how he was
going to use that later in the book (he always did end up using or referencing
it). I understand that foreshadowing is neat, but it felt a little obvious.&lt;/p&gt;
&lt;p&gt;Some of the hacking felt unrealistic. Even within the context of a SciFi
universe, it doesn't seem like these sensitive systems should be so easily
hackable.&lt;/p&gt;
&lt;p&gt;Despite these criticisms, this was a very enjoyable read. Admittedly, I'm a
nerd, so I don't know how the reference-laden prose would feel to someone who's
not a fan of nerdy books and games. The book never felt like it was dragging,
which made reading it a good time.&lt;/p&gt;
&lt;h2&gt;Oblivion: Stories, David Foster Wallace&lt;/h2&gt;
&lt;p&gt;This book is a collection of eight short stories. Of these, I found three to be
wonderful, four or five to be good, and the other one or two weren't my cup of
tea.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Incarnations of Burned Children&lt;/em&gt; is short, gripping, and emotional. Wallace
does an excellent job of making the story seem real and important.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Another Pioneer&lt;/em&gt; is a story about an ancient society told through two or three
retellings. The levels of redirection allow Wallace to explore some narrative
branching patterns I found fascinating.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Good Old Neon&lt;/em&gt; is a story about a man who looks introspectively and finds
within himself nothingness. His attempts at dealing with this discovery are
interesting.&lt;/p&gt;
&lt;p&gt;I noticed two common patterns among all the stories. First, I often started
reading, got a few pages in, started to think to myself "This one's kinda
boring...", and then suddenly Wallace would introduce something that hooked me.&lt;/p&gt;
&lt;p&gt;Second, most (maybe all) of the stories end with a level of ambiguity. Because
of this, the stories left me thinking about them on and off in the days after
reading them.&lt;/p&gt;
&lt;p&gt;Reading this book was well worth my time.&lt;/p&gt;</description><author>Samuel Taylor</author><guid isPermaLink="true">https://www.samueltaylor.org/articles/books-june16.html?utm_source=rss&amp;utm_campaign=st-blog-feed</guid><pubDate>Sun, 26 Jun 2016 11:04:55 GMT</pubDate></item><item><title>The Last 5 Books I Read (February 2016)</title><link>https://www.samueltaylor.org/articles/books-feb.html?utm_source=rss&amp;utm_campaign=st-blog-feed</link><description>&lt;h2&gt;Redirect, Timothy Wilson&lt;/h2&gt;
&lt;p&gt;A book from a college professor about his (and others') research in "story
editing" techniques that target the narratives we tell ourselves. I particularly
appreciated the thoughts on happiness, as those are the most widely applicable.
Because I'm not a parent, I couldn't quite get into the stuff about parenting as
much. The discussions of various societal issues and how they might be addressed
were also interesting, but not particularly applicable to my life.&lt;/p&gt;
&lt;h2&gt;The Martian, Andy Weir&lt;/h2&gt;
&lt;p&gt;I liked this book a lot. The attention to detail made it feel very real and
interesting. The point of view from which it is written adds a lot of tension
and excitement. As an aside, I enjoyed the book much more than the movie
because the book is more detailed and the writing style is enjoyable.&lt;/p&gt;
&lt;h2&gt;Deep Work, Cal Newport&lt;/h2&gt;
&lt;p&gt;The first 30% of the book is an argument for why deep work is necessary in
today's economy. That 30% is good, but I was already convinced of the value of
what he calls "deep work," so they weren't the most interesting thing I've read.&lt;/p&gt;
&lt;p&gt;He has many good suggestions. One I've liked so far is to keep a sort of
deep work scoreboard, where you log how many hours of deep work you get in each
day. Then, in your weekly review, you can use that data to keep yourself
accountable. This suggestion comes out of the idea of focusing on &lt;em&gt;lead
measurements&lt;/em&gt;, which is itself a good idea. If you have a goal (e.g. get more
personal projects done), the obvious way to measure your progress on that goal
(e.g. how many projects you've finished) is often a &lt;em&gt;lag measure&lt;/em&gt;. That is, by
the time you see the improvement on the lag measure, you've already made the
improvements in your personal processes which allowed for it. By contrast, lead
measurements help you quantify the change in your personal processes that will
ultimately enable you to achieve the goal you're working toward.&lt;/p&gt;
&lt;h2&gt;Coders at Work, Peter Seibel&lt;/h2&gt;
&lt;p&gt;This is a book of interviews with notable programmers. While some of the stories
seem dated (most of the people in the book got their start decades ago), it's
interesting to read others' reflections on programming.&lt;/p&gt;
&lt;p&gt;A detail I like is that several interviewees mention how important reading other
people's code is. I didn't really read much code until I did an internship at a
software company, and then I almost felt like I was drowning in it. One company
I worked for practiced "self-documenting code," so the way I learned what
certain pieces of code was simply to read it. Once I got used to it, I liked
this system. That internship was the first time I really understood the value of
readable code.&lt;/p&gt;
&lt;p&gt;Douglas Crockford talks about code quality in an interesting way. I like the
idea of taking every seventh sprint to focus on improving the codebase. One of
my employers did not focus on code quality, and their company suffered for it.
At a certain point it becomes difficult to retain developers when the codebase
makes it harder to develop and easier to introduce bugs. I'm sure they didn't
intend to get to that point, which demonstrates the importance of understanding
quality as an ongoing process.&lt;/p&gt;
&lt;p&gt;I enjoyed Joshua Bloch's thought that some coding is more similar to writing
prose than it is to mathematics. The way he talks about creating good API's and
readable code inspires me to be a better programmer and designer.&lt;/p&gt;
&lt;h2&gt;The Two Towers, J.R.R. Tolkien&lt;/h2&gt;
&lt;p&gt;Another interesting book in the series. The sense of adventure and the grandness
of the world make reading this book enjoyable.&lt;/p&gt;
&lt;p&gt;I want to be Treebeard when I grow up. He's such an interesting character, and I
think his orientation to time is very interesting. A detail I like in particular
is that his name in the ent language is very long, as ents believe that names
should tell something of the thing's story.&lt;/p&gt;
&lt;p&gt;At times, I get lost in all the detail and have difficulty keeping my mental
picture straight. Perhaps I would gain more out of the reading if I were to hold
on to more details, but that feels like more work than I want to put into
reading this book. I don't mean to be lazy; I would just rather spend my mental
energy elsewhere. Though I lack a lot of the detail (the geography of the area,
for instance, is completely lost on me), I feel like I understand the story well
still, and I still enjoy reading it.&lt;/p&gt;</description><author>Samuel Taylor</author><guid isPermaLink="true">https://www.samueltaylor.org/articles/books-feb.html?utm_source=rss&amp;utm_campaign=st-blog-feed</guid><pubDate>Sat, 20 Feb 2016 14:13:01 GMT</pubDate></item><item><title>Useful Python language features for interviews</title><link>https://www.samueltaylor.org/articles/python-tools-for-interviews.html?utm_source=rss&amp;utm_campaign=st-blog-feed</link><description>&lt;h2&gt;&lt;code&gt;collections.namedtuple&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;namedtuple&lt;/code&gt; can make your code a lot more readable. In an interview, that's
helpful for a few reasons. First, it can help you demonstrate a good
understanding of some of Python's standard libraries. Second, it helps you show
off that you place importance on writing readable code. Third, it makes writing
your code easier. If you're passing around tuples, it can be easy to forget
what the object at each index into the tuple is. Using a &lt;code&gt;namedtuple&lt;/code&gt; can help
you avoid that.&lt;/p&gt;
&lt;p&gt;Consider the case where you need to represent colors. You could choose to do so
with a 3-tuple of the form &lt;code&gt;(i, j, k)&lt;/code&gt; (where &lt;code&gt;i&lt;/code&gt;, &lt;code&gt;j&lt;/code&gt;, and &lt;code&gt;k&lt;/code&gt; are integers on
the range 0-255). This representation seems intuitive and natural enough. &lt;code&gt;i&lt;/code&gt;
could be the value for red, &lt;code&gt;j&lt;/code&gt; for green, and &lt;code&gt;k&lt;/code&gt; for blue. A problem with this
approach is that you may forget which of the three numbers represents which
primary color of light. Using a &lt;code&gt;namedtuple&lt;/code&gt; could help with this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Color = namedtuple('Color', ['red', 'green', 'blue'])
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What does this change? Well, building a &lt;code&gt;Color&lt;/code&gt; is almost the same as building
that tuple you were previously building. Instead of doing &lt;code&gt;(i, j, k)&lt;/code&gt;, you'll
now write &lt;code&gt;Color(i, j, k)&lt;/code&gt;. This is perhaps a little more readable, and it adds
some more semantic meaning to your code. We're no longer just building a tuple;
we're building a &lt;code&gt;Color&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The real win for &lt;code&gt;namedtuple&lt;/code&gt; is in access to its elements.  Before, to get the
red value for a color &lt;code&gt;c&lt;/code&gt;, we would use brackets: &lt;code&gt;c[0]&lt;/code&gt;. By comparison, if we
have a &lt;code&gt;Color&lt;/code&gt; called &lt;code&gt;c&lt;/code&gt;, we could use a more friendly dot syntax: &lt;code&gt;c.red&lt;/code&gt;. In
my experience, while not having to remember the index of the red element is
nice, the real win is in how much more readable &lt;code&gt;c.red&lt;/code&gt; is in contrast to
&lt;code&gt;c[0]&lt;/code&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;code&gt;collections.defaultdict&lt;/code&gt; and &lt;code&gt;collections.Counter&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;Suppose your interviewer asks you to find the most common string in a list of
strings. We can solve this problem using a &lt;code&gt;defaultdict&lt;/code&gt; (let's call it &lt;code&gt;d&lt;/code&gt;). We
could loop through the list, incrementing &lt;code&gt;d[elem]&lt;/code&gt; for each element. Then, we
just find the one we saw most. The implementation would look like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;def most_common_dd(lst):
    d = defaultdict(int)
    for e in lst:
        d[e] += 1

    return max(d.iteritems(), key=lambda t: t[1])
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Apparently, users and maintainers of Python saw this pattern enough that they
decided to create &lt;code&gt;Counter&lt;/code&gt;. &lt;code&gt;Counter&lt;/code&gt; lets us write a much more succinct
version of this function, because &lt;code&gt;Counter&lt;/code&gt; encapsulates the process of counting
the number of ocurrences of elements in an iterable. Implementing this
functionality with a `Counter object would look like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;def most_common_ctr(lst):
    return Counter(lst).most_common(1)[0]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These both have the same result:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;from collections import Counter, defaultdict

strings = ['bear', 'down', 'you', 'bears', 'of', 'old', 'baylor', 'u', "we're",
        'all', 'for', 'you', "we're", 'gonna', 'show', 'dear', 'old', 'baylor',
        'spirit', 'through', 'and', 'through', 'come', 'on', 'and', 'fight',
        'them', 'with', 'all', 'your', 'might', 'you', 'bruins', 'bold', 'and',
        'win', 'all', 'our', 'victories', 'for', 'the', 'green', 'and', 'gold']

'''
definitions for most_common_ctr and most_common_dd
'''

assert most_common_dd(strings) == most_common_ctr(strings)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But the version using &lt;code&gt;Counter&lt;/code&gt; is more concise.&lt;/p&gt;
&lt;h2&gt;Comprehensions&lt;/h2&gt;
&lt;p&gt;I love list comprehensions. They can make code much more concise and readable.
Consider a problem where we have a start point and an end point on a grid:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;|S|_|_|_|
|_|_|_|_|
|_|_|_|_|
| | | |E|
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let's further say that from a given cell, you can travel up, down, left or right
into another cell (but not diagonally). We may want to do a bread-first search
to find the minimum cost to get from the start to the end. At some point, we'll
need to push the neighbors of the current cell onto the queue we're using for
the BFS. This could look something like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;for neigh in neighbors(cell):
    # validate neigh
    queue.append(neigh)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;How should &lt;code&gt;neighbors(cell)&lt;/code&gt; work? Well, we could use a double for loop to
generate the neighbors:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;def neighbors(cell):
    for i in range(-1, 2):
        for j in range(-1, 2):
            if i == 0 and j == 0 or abs(i) + abs(j) &amp;gt; 1:
                continue
            yield (cell[0] + i, cell[0] + j)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This works, but it's ugly. Instead, we could use a list comprehension:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;DIRS = [(0, 1), (0, -1), (1, 0), (-1, 0)]
def neighbors(cell):
    return [(cell[0] + d[0], cell[1] + d[1]) for d in DIRS]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We're also probably going to want to keep track of which cells we've already
visited (so we don't try to go back through them). We could create a matrix of
&lt;code&gt;bool&lt;/code&gt;s the same size as our original grid (let's call it &lt;code&gt;visited&lt;/code&gt;) and set
&lt;code&gt;visited[r][c]&lt;/code&gt; when we visit the cell located at row &lt;code&gt;r&lt;/code&gt; and column &lt;code&gt;c&lt;/code&gt;. But
how should we initialize this matrix? We could do something like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;visited = []
for i in range(n):
    visited.append([])
    for j in range(n):
        visited[i].append(False)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But list comprehensions can make this much more concise:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;visited = [[False for _ in range(n)] for _ in range(n)]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The possibilities with list comprehensions are just about endless, so I'll leave
it at that!&lt;/p&gt;</description><author>Samuel Taylor</author><guid isPermaLink="true">https://www.samueltaylor.org/articles/python-tools-for-interviews.html?utm_source=rss&amp;utm_campaign=st-blog-feed</guid><pubDate>Sat, 17 Oct 2015 11:03:09 GMT</pubDate></item><item><title>Hackathon report: TAMUHack 2015</title><link>https://www.samueltaylor.org/articles/tamuhack-2015.html?utm_source=rss&amp;utm_campaign=st-blog-feed</link><description>&lt;h2&gt;Idea&lt;/h2&gt;
&lt;p&gt;Two weeks ago, &lt;a href="/articles/hacktx-2015.html"&gt;I went to HackTX&lt;/a&gt; and won a Leap
Motion. While thinking about what things we could build with skeletal tracking
and gesture recognition, I thought it would be cool to build a language learning
tool (like Rosetta Stone) for American Sign Language. My friend
&lt;a href="http://matttinsley.org/"&gt;Matt&lt;/a&gt; also thought it sounded cool, so we decided to
build something like that at TAMUHack.&lt;/p&gt;
&lt;h2&gt;Environment&lt;/h2&gt;
&lt;p&gt;TAMUHack was fun. The venue was called "The Zone", which is a big room in A&amp;amp;M's
stadium. All 300 of us were in this massive room, along eight big tables. Being
in the same room as everyone else was really cool; you felt like you were all a
part of something. I've been to other hackathons where I've not been able to
find a seat in the main areas; being separated from the rest of the teams is not
fun. The organizers of TAMUHack found a great solution to that problem--put
everyone together!&lt;/p&gt;
&lt;h2&gt;Project evolution&lt;/h2&gt;
&lt;p&gt;We started to build something that would simply transcribe signs of the ASL
alphabet as a user signed them above the Leap Motion. By around
&lt;a href="https://github.com/ssaamm/sign-language-tutor/commit/35aac3168fd37a984087dc269607aa815e382fc8"&gt;3:00am&lt;/a&gt;,
we had that more or less working. Playing around with it, we knew it definitely
wasn't perfect, but it showed promise.&lt;/p&gt;
&lt;p&gt;The Leap Motion is not particularly well-suited to sign language recognition. In
our research during the hackathon, we found a research paper that said the Leap
Motion in its current state &lt;a href="http://www98.griffith.edu.au/dspace/bitstream/handle/10072/59247/89839_1.pdf"&gt;isn't a good choice for recognizing Australian Sign
Language&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;As an initial run at solving this, we decided to implement some simple Markov
chain analysis. The idea was that if certain letters commonly precede others, we
should be able to figure out that a person signing "q" will probably sign "u"
next. That idea didn't end up helping us out all that much; we tore it out
later. After we input some more training data, the recognition was good enough
that we could work with it.&lt;/p&gt;
&lt;p&gt;At that point, we had some time left and felt like we could keep going to make
something cooler than what we had. We decided to make the language learning tool
we'd originally planned on making. By
&lt;a href="https://github.com/ssaamm/sign-language-tutor/commit/90bed1fbe605bec0932b3ccb6e41e685dc70ea3b"&gt;8:00am&lt;/a&gt;,
we had a basic version working. The app would show you a picture of a sign and
ask you to replicate it. Once you had, it would give you 100 points and pick
another sign for you to make. After 30 seconds, you could enter your score on
our leaderboard. We decided to make our project into a game because it seemed
like a fun way to demo the tech we had built.&lt;/p&gt;
&lt;p&gt;We ended up
&lt;a href="https://github.com/ssaamm/sign-language-tutor/commit/c0fb39b539a579419516ae6e6bcfc2b59452caf2"&gt;finishing&lt;/a&gt;
about an hour before projects were due. We were so happy to have built something
so cool and fun to make in such a short amount of time.&lt;/p&gt;
&lt;h2&gt;Presentations&lt;/h2&gt;
&lt;p&gt;We set up our area with our laptops and the two external monitors we brought. We
each ran a copy of our app on an external monitor and had the Leap Motion
visualizer on our laptop screens. This ended up being super useful; we could
show people what the Leap Motion was seeing in real time.&lt;/p&gt;
&lt;p&gt;Getting to show off our project to judges and other hackers was super fun.
People thought it was super cool and were excited to play around with it.&lt;/p&gt;
&lt;p&gt;We got into the top six and were asked to present at closing cermonies. Awesome!
It was a little rushed because things were running late, but I still enjoyed
getting to talk about our hack in front of everyone.&lt;/p&gt;
&lt;p&gt;Apparently the judges also thought it was cool, because Matt and I won second
place overall!&lt;/p&gt;
&lt;h2&gt;Thanks&lt;/h2&gt;
&lt;p&gt;TAMUHack was super fun. Huge thanks to the organizers, volunteers, and judges.&lt;/p&gt;</description><author>Samuel Taylor</author><guid isPermaLink="true">https://www.samueltaylor.org/articles/tamuhack-2015.html?utm_source=rss&amp;utm_campaign=st-blog-feed</guid><pubDate>Sun, 11 Oct 2015 10:39:45 GMT</pubDate></item><item><title>Political implications of BitTorrent</title><link>https://www.samueltaylor.org/articles/bittorrent.html?utm_source=rss&amp;utm_campaign=st-blog-feed</link><description>&lt;p&gt;BitTorrent is an inherently political technology which embodies decentralized
political order. Additionally, it broadens the definition of art. Despite the
negative side effects of the technology, BitTorrent is worth pursuing.&lt;/p&gt;
&lt;p&gt;What does it mean to say that a technology is political? Winner outlines two
possibilities:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I…offer…two ways in which artifacts can contain political properties. First
are instances in which the invention, design, or arrangement of a specific
technical device or system becomes a way of settling an issue in a particular
community.  Second are cases of what can be called inherently political
technologies, man-made systems that appear to require, or to be strongly
compatible with, particular kinds of political relationships.…By ”politics,” I
mean arrangements of power and authority in human associations as well as the
activities that take place within those arrangements.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;What does it mean to say that a technology embodies decentralized political
order? Applying Winner’s thought, such a technology would either appear to
require or be strongly compatible with a kind of arrangement of power and
authority with regard to human associations and activities within such
associations. Inasmuch as the information age has made information power, to say
that a technology is strongly compatible with decentralized political
relationships means that the technology decentralizes control of information. We
would expect such technologies to be dangerous to centralized power structures.&lt;/p&gt;
&lt;p&gt;BitTorrent decentralizes control of information, and thereby embodies
decentralized political order. Each person in the swarm has the power to
download the information, and each person in the swarm also has the
responsibility to upload the information to their peers. In fact, with the usage
of distributed hash table technology, even a centralized tracker is unnecessary;
peers can coordinate file transfer themselves without the need for a tracker
(BitTorrent.org).&lt;/p&gt;
&lt;p&gt;Decentralization of information control and access is the natural end of
BitTorrent. Imagine that BitTorrent exists in some centralized power structure
where only one torrent tracker exists. In order for some authoritarian,
centralized power to keep said power, it would have to be able to keep control
over the way that BitTorrent is used. And for a time, that central power could
control BitTorrent. But starting a new tracker is so easy that controlling such
action over a long period of time would be almost impossible. To prevent people
from starting new trackers and attracting users away from the Official TrackerTM
would require coercion on a scale that is hard to imagine, let alone implement.&lt;/p&gt;
&lt;p&gt;Furthermore, BitTorrent is dangerous to centralized power structures. Look at
the example of music. Record labels are a powerful, centralized entity in the
realm of music. If BitTorrent is a threat to centralized power, then we should
expect to see record labels seeking to control BitTorrent. The Recording
Industry Association of America (an organization made of record
labels/distributors) seeks to exercise control over the ways in which people use
BitTorrent. The RIAA targets both users and trackers, attempting to get such
high punishments as to scare people away from using BitTorrent for sharing
music.&lt;/p&gt;
&lt;p&gt;Consider another example of a centralized power structure: the People’s Republic
of China. China censors much of the internet and has started to censor
BitTorrent websites (Van der Sar). These two examples of centralized powers
fighting to control BitTorrent provide a compelling argument that there is
something about BitTorrent which encourages decentralization of power.&lt;/p&gt;
&lt;p&gt;Another way that BitTorrent decentralizes power is in the way that people
discover content. Again, consider the example of music. In the past, certain
people have had much more power over the sharing of music than others; radio
DJ’s, journalists, and the like were able to exert power over the music people
listen to. Before the advent of peer-to-peer technology, a non-DJ’s ability to
share music with others was limited to those physically/geographically nearby.
Peer-to-peer technology allows for music sharing to occur through the internet;
a user can now share her favorite music with anyone (Franchini). BitTorrent
enables users to share not only the knowledge of some song or artist, but the
very music itself.&lt;/p&gt;
&lt;p&gt;Perhaps the most beneficial societal contribution offered by BitTorrent is the
decentralization of content distribution. It allows creation and distribution of
art to happen without the support of powerful backers. Before BitTorrent,
distributing a television show required some power over the broadcasters. Even
in the internet age, the bandwidth costs of distributing a “television” show can
be very expensive. The unique opportunity afforded by BitTorrent is to share the
load of distributing the content among a large “swarm” of peers. Because it
drives distribution costs down, BitTorrent liberates content creators from
distributors; they can distribute their own content.&lt;/p&gt;
&lt;p&gt;It also changes the ways in which users support their favorite artists. In a
world overwhelmed with file sharing, supporting an artist has become less about
buying the artist’s physical records/CD’s and more about buying band merchandise
and tickets to concerts (Franchini). This change in artists’ revenue models from
being primarily based on selling albums to being based on selling concert
tickets and merchandise is also recognized by the artists themselves. Winston
Marshall, the guitarist for Mumford &amp;amp; Sons, says that “Music is changing.…We
look at our albums as…adverts for our live shows” (Stern).&lt;/p&gt;
&lt;p&gt;Combining these effects, BitTorrent decreases the distance between content
creators and content consumers, thereby encouraging more people to become
content creators. Consumers no longer must go through a middle man to access
their favorite creators’ work. They also take an active role in the re-creation
of said work. As a result, consumers develop more direct relationships with the
creators of content they like. Finally, because distribution costs are lower,
consumers are more likely to become creators, and they will not have to seek the
help of powerful distribution/broadcasting middle men. BitTorrent removes the
necessity for a powerful middle man.&lt;/p&gt;
&lt;p&gt;A counter-argument to the claim that BitTorrent embodies decentralizes power is
that certain players in the BitTorrent ecosystem possess more power than others.
The Pirate Bay, for instance, is a huge tracker which has lots of power.
However, the existence of powerful players within a system does not imply a lack
of decentralization of power. Users can still choose whether to use the
mega-websites or the smaller ones. An abundance of torrent websites still exist
and have power. This means that even though some are more powerful than others,
power is largely decentralized in the BitTorrent ecosystem.&lt;/p&gt;
&lt;p&gt;This decentralization of power is a good thing. Distributed power is inherently
good in a society which values not being dominated by another person. If power
is centralized, then the entity with the power is able to dominate whomever they
so desire. American society values not being dominated, so this decentralization
of power brought about by BitTorrent is good for society.&lt;/p&gt;
&lt;p&gt;Another effect of BitTorrent (distinct from the decentralization of power) is
that it changes what the word “art” means. Rodriguez-Ferrandiz dicsusses the
effect that digital copies have on art as a whole in an abstract sense. In
essence, the importance of the “original” work becomes less important.
Possessing the original version of a song does not matter all that much when
every copy of a song is perfect. In that BitTorrent makes the recreation of art
extremely inexpensive and completely accurate, the quality and accessibility of
copies of individual works of art mean that having the original is not
significantly better than having a copy for most individuals.&lt;/p&gt;
&lt;p&gt;Rodriguez-Ferrandiz specifically writes of photography, noting that it has
caused “the focus of interest” to switch “from the work as a singularity that
physically retains the creator’s touch to a vision of the work as a multipliable
and liberated piece which removes distinctions between original and copy”. An
earlier author, Benjamin, who is cited by Rodriguez-Ferrandiz refers to the
distinction between original and copy as the “aura.” What of digital art, then,
for which there is no difference between originals and copies?
Rodriguez-Ferrandiz argues that a “paradoxical aura” exists for such art.
Because the art is not defined by the way that it is represented in binary on a
hard disk, it “transcends physical form” and becomes “immortal.” Though
BitTorrent does not qualitatively change this trend or contribute to it in a
novel way, it does offer a quantitatively larger realization of this immortality
by making the reproduction of digital art far easier.&lt;/p&gt;
&lt;p&gt;This change in the meaning of art is a good thing. It broadens art to include
digital arts, giving artists a new medium for creativity. In American society,
creativity is valued, so this change is good for society.&lt;/p&gt;
&lt;p&gt;Of course, the technology is not without its drawbacks. Nothing inherent to the
protocol stops its use from including mass distribution of child pornography or
other unquestionably bad things. The entire idea of decentralized control is
antithetical to the censorship of BitTorrent as a medium (whether or not the
censorship is of things society generally agrees are bad). The government will
not be able to stop the spread of child pornography through BitTorrent.&lt;/p&gt;
&lt;p&gt;This inability to censor terrible things is not a reason to stop usage of
BitTorrent technologies. First, this problem is not unique to BitTorrent. Many
technologies make spreading morally repulsive content much easier (e.g. the
internet, books, compact disks, pencils). Second, BitTorrent requires a large
swarm of users for effectiveness. To say that certain things are generally
agreed upon to be unacceptable in a society implies that the number of people
who will participate in such behavior is low. Thus, BitTorrent is a bad fit for
child pornographers and sharers of other repulsive content.&lt;/p&gt;
&lt;p&gt;BitTorrent embodies decentralized political order. It broadens the definition of
art. Because these are both good things, BitTorrent is a technology that is
worth pursuing despite its drawbacks.&lt;/p&gt;
&lt;h2&gt;Works cited&lt;/h2&gt;
&lt;p&gt;BitTorrent.org. “BEP 5: DHT Protocol.” &lt;a href="http://www.bittorrent.org/beps/bep_0005.html"&gt;Link&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Van der Sar, Ernesto. “China Hijacks Popular BitTorrent Sites.” TorrentFreak. 8
Nov 2008.&lt;/p&gt;
&lt;p&gt;Rodriguez-Ferrandiz, Raul. “Benjamin, BitTorrent, bootlegs: auratic piracy
cultures?.” International journal of communication.&lt;/p&gt;
&lt;p&gt;Stern, Marlow. “Mumford &amp;amp; Sons Diss Jay Zs Tidal.” The Daily Best. 12 April
2015.&lt;/p&gt;
&lt;p&gt;Winner, Langdon. “Do Artifacts Have Politics?” Daedalus, Vol. 109, No. 1, Modern
Technology: Problem or Opportunity? (Winter, 1980), pp. 121-136. &lt;/p&gt;</description><author>Samuel Taylor</author><guid isPermaLink="true">https://www.samueltaylor.org/articles/bittorrent.html?utm_source=rss&amp;utm_campaign=st-blog-feed</guid><pubDate>Wed, 07 Oct 2015 20:42:24 GMT</pubDate></item><item><title>Hackathon report: HackTX 2015</title><link>https://www.samueltaylor.org/articles/hacktx-2015.html?utm_source=rss&amp;utm_campaign=st-blog-feed</link><description>&lt;h2&gt;Idea&lt;/h2&gt;
&lt;p&gt;My team and I started thinking of ideas on the drive down to Austin. We ended up
deciding to do something that would automate the scheduling of meetings.&lt;/p&gt;
&lt;h2&gt;Project&lt;/h2&gt;
&lt;p&gt;We started writing a Python/Flask app hosted on Azure. Getting the project
deployed initially was easy, as was setting up continuous integration. Last
year, we wrote a PHP web app, and none of us were able to use our computers to
test. In essence, the production server was also our development server. Using
Flask was awesome because it comes with a development server.&lt;/p&gt;
&lt;p&gt;Wes started to work on the UI, I worked on figuring out a way to read people's
emails with Context.IO, and Evan worked on user account management. He started
to use Flask-User, but then we couldn't get it to work on the Azure
configuration we had set up. It was late at night, I wasn't sure what other
library to use, and Wes was starting to hate Python, so we made a hard decision
and switched everything to PHP.&lt;/p&gt;
&lt;p&gt;At this point, we had to set up DeployBot to do continuous integration, and we
went back to the issue of not having servers to do development on. As a result,
the git log got pretty terrible.&lt;/p&gt;
&lt;p&gt;I got a script to check a user's email inbox for emails that looked like someone
trying to schedule a meeting and set it up to run on a cron job while Evan
worked on our SendGrid integration.&lt;/p&gt;
&lt;p&gt;The actual scheduling logic came into play much later in the day than we would
have hoped. Luckily, it didn't turn out to be too challenging, so we were able
to get it implemented and finally create our app's core functionality.&lt;/p&gt;
&lt;p&gt;In the end, our product was definitely more hacky than any of us would have
liked, but it worked well enough to demonstrate.&lt;/p&gt;
&lt;h2&gt;Presentation&lt;/h2&gt;
&lt;p&gt;Once again, presentations were "science fair" style this year, which was great.
Several judges came around and asked about our project. Our pitch was something
like this:&lt;/p&gt;
&lt;p&gt;I've been doing job hunting lately, which involves a good amount of emailing
back and forth to coordinate interviews. This process is a tedious chore; sounds
like a job for computers! We built Schedule Ninja, an awesome computerized ninja
that slices and dices your meetings so you don't have to.&lt;/p&gt;
&lt;p&gt;Users log in with their Google account, which we use to pull in their
availability through Google Calendar. We read their email in order to find
messages that look like someone trying to set up a meeting. From those emails,
we generate a request on the user's dashboard that they can either accept or
deny. If they accept the request, Schedule Ninja emails the requester back with
the user's availability and asks them to click a link to confirm their meeting
time.&lt;/p&gt;
&lt;p&gt;Schedule Ninja can also be used to request a meeting with someone else. The user
types in an email address, and we detect whether that person is on our service.
If they are, we are able to avoid email altogether, compare the two people's
schedules, and set up a meeting for them automatically.&lt;/p&gt;
&lt;p&gt;We got some great feedback from several judges who wanted to sign up for the
service immediately. That felt very validating; we had built something users
actually wanted! Unfortunately, we didn't place overall, but we did end up
winning sponsor prizes from Microsoft and Indeed.&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;We had a lot of fun and built a useful product in 24 hours. Big thanks to the
HackTX organizers, Context.IO, Square, Microsoft, and Indeed for all their
feedback and help. If you've not gone to a hackathon, you should definitely sign
up! They're super fun!&lt;/p&gt;
&lt;p&gt;If you want to get in touch for any reason, I can be reached at
sgt@samueltaylor.org. Thanks!&lt;/p&gt;</description><author>Samuel Taylor</author><guid isPermaLink="true">https://www.samueltaylor.org/articles/hacktx-2015.html?utm_source=rss&amp;utm_campaign=st-blog-feed</guid><pubDate>Mon, 28 Sep 2015 20:36:29 GMT</pubDate></item><item><title>The 10 Best Ingredients for Cheap Cooking</title><link>https://www.samueltaylor.org/articles/best-ingredients-for-cheap-cooking.html?utm_source=rss&amp;utm_campaign=st-blog-feed</link><description>&lt;p&gt;The ten most frequently-used ingredients on &lt;a href="http://budgetbytes.com"&gt;Budget
Bytes&lt;/a&gt; are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Salt&lt;/li&gt;
&lt;li&gt;Garlic&lt;/li&gt;
&lt;li&gt;Olive oil&lt;/li&gt;
&lt;li&gt;Eggs&lt;/li&gt;
&lt;li&gt;Brown sugar&lt;/li&gt;
&lt;li&gt;Oregano&lt;/li&gt;
&lt;li&gt;Water&lt;/li&gt;
&lt;li&gt;Cumin&lt;/li&gt;
&lt;li&gt;Yellow onion&lt;/li&gt;
&lt;li&gt;Pepper&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This information was gathered using a &lt;a href="https://github.com/ssaamm/recipe-scraper/"&gt;scraper I
wrote&lt;/a&gt; with Python 3, BeautifulSoup,
and Requests.&lt;/p&gt;</description><author>Samuel Taylor</author><guid isPermaLink="true">https://www.samueltaylor.org/articles/best-ingredients-for-cheap-cooking.html?utm_source=rss&amp;utm_campaign=st-blog-feed</guid><pubDate>Sat, 12 Sep 2015 10:51:54 GMT</pubDate></item><item><title>Thoughts on Effective Java</title><link>https://www.samueltaylor.org/articles/effective-java.html?utm_source=rss&amp;utm_campaign=st-blog-feed</link><description>&lt;p&gt;I'm reading the second edition of &lt;em&gt;Effective Java&lt;/em&gt; in a group at work and
writing some thoughts/notes about it here.&lt;/p&gt;
&lt;h2&gt;Chapter 2&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Item 1&lt;/strong&gt; is about static factory methods.&lt;/p&gt;
&lt;p&gt;The leader of my group offered a point that static factory methods can be hard
to mock. I don't have a ton of experience at this time with mocking objects, so
I haven't seen that first hand, but I'll trust him and keep it in mind for the
future.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Item 1, advantage 4&lt;/strong&gt; says that static factory methods are good because they
reduce verbosity in creating objects. The example they give is:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Map&amp;lt;String, List&amp;lt;String&amp;gt;&amp;gt; m = new HashMap&amp;lt;String, List&amp;lt;String&amp;gt;&amp;gt;();
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Java 7 introduces the diamond operator, so this can become:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Map&amp;lt;String, List&amp;lt;String&amp;gt;&amp;gt; m = new HashMap&amp;lt;&amp;gt;();
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;thereby negating the verbosity-decreasing benefit of static factory methods.&lt;/p&gt;
&lt;p&gt;I'm not trying to say the book is wrong. It says "Revised and Updated for
Java SE 6" on the cover, and for Java 6, that seems like a valid argument. I
just think it's interesting how new language features can change what constitues
a best practice. The book even says, "Someday the language may perform this sort
of type inference on constructor invocations as well as method invocations."&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Item 2&lt;/strong&gt; is about builders.&lt;/p&gt;
&lt;p&gt;In the process of talking about builders, the author talks about the JavaBeans
pattern. This pattern seems like a terrible idea to me; forgetting to set a
required parameter is relatively easy and could have disastrous results. The
Builder pattern seems like a better choice because it's a way to give the
compiler more information. I would rather have my IDE yell at me at compile time
that my object isn't instantiated correctly than wrestle with bugs at run time.&lt;/p&gt;
&lt;p&gt;Builders do introduce more code to write/maintain/test, but (as my group leader
pointed out) the IDE can generate the class for you.&lt;/p&gt;
&lt;p&gt;The book has required parameters going in the builder's constructor and optional
parameters being set by additional methods. My question is: what if the number
of required parameters gets large? Then you haven't solved your problem at all.
One option would be to move the required parameters into methods, but then
you're not providing the compiler with the information to know that some of the
parameters are required. Yes, the &lt;code&gt;build()&lt;/code&gt; method can check for them and
perhaps throw an exception, but that only happens at run time.&lt;/p&gt;
&lt;p&gt;I think that if you have so many required parameters, there might be something
wrong with your design. Perhaps some arguments are logically related and should
be combined into an instance of a new class which binds them together. I'm not
sure if this is always the case, but it seems like it often would be.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Item 3&lt;/strong&gt; talks about singletons.&lt;/p&gt;
&lt;p&gt;Our group leader told us to beware of the hidden state that often comes along
with singletons. I have definitely run into that issue. When functions use state
that is not from a parameter, things can get tricky. Knowing what state is used
and how that will affect the execution of the function can be difficult for the
developer.&lt;/p&gt;
&lt;p&gt;While the book says that, "a single-element enum type is the best way to
implement a singleton," our leader disagreed. He argues that using an &lt;code&gt;enum&lt;/code&gt; is
less readable. I had a similar gut feeling when I first read this part of the
Item; I would not have thought to use an &lt;code&gt;enum&lt;/code&gt; to implement a singleton. In my
mind, an &lt;code&gt;enum&lt;/code&gt; represents an enumeration of a few different kinds of things; a
singleton is something that there will only ever be one of. These two ideas seem
at odds.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Item 4&lt;/strong&gt; talks about noninstantiable classes. These classes are often used for
utility methods.&lt;/p&gt;
&lt;p&gt;Again, apparently static things are difficult to mock. And Java's garbage
collector has apparently gotten good enough that doing something like &lt;code&gt;(new
FileUtility()).getPermissions(file)&lt;/code&gt; will result in the created &lt;code&gt;FileUtility&lt;/code&gt;
being garbage collected very quickly. This all happens fast enough that there is
very little performance impact.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Item 7&lt;/strong&gt; says to avoid finalizers. I learned C++ in school, so the lack of
guarantees with finalizers throws me off. In any case, I've never heard someone
seriously advocate for finalizer usage.&lt;/p&gt;
&lt;h2&gt;Chapter 3&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Item 8&lt;/strong&gt; is about the general contract for equals. The terms used in the
contract are familiar from discrete math.&lt;/p&gt;
&lt;p&gt;For value objects, you want to override &lt;code&gt;equals()&lt;/code&gt;. &lt;code&gt;equals()&lt;/code&gt; gets tricky when
inheritance comes into play, though. One solution to that problem is to not use
inheritance with value object -- make your value objects &lt;code&gt;final&lt;/code&gt;. Inheritance
can be useful for business logic, so feel free to use inheritance in that case.
For classes that implement business logic, though, it doesn't make much sense to
implement &lt;code&gt;equals()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;An interesting thing I hadn't thought about is that &lt;code&gt;instanceof&lt;/code&gt; checks for
null:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public class Main
{
    public static void main(String[] args)
    {
        String nullString = null;
        System.out.println(nullString instanceof String);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Output:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;false
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;One suggestion was to use an &lt;code&gt;EqualsBuilder&lt;/code&gt;, like the one supplied in Apache
Commons. Apparently, equals builders will help you avoid NPE's. To me, this
seems like a cop-out. I don't think it's too terribly difficult to avoid writing
an &lt;code&gt;equals()&lt;/code&gt; method which won't throw an NPE; perhaps I haven't written enough
Java.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Item 9&lt;/strong&gt; is about &lt;code&gt;hashCode()&lt;/code&gt;. Equal objects must have equal hash codes.&lt;/p&gt;
&lt;p&gt;The book contains an overview of how to write a &lt;code&gt;hashCode()&lt;/code&gt; method that's good
enough. Ground-breaking, cutting-edge, crazy high-performance hashing functions
are going to be class-specific. Sometimes, this is fairly obvious; if your class
has a unique ID, you can just return that as your hash code.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Item 10&lt;/strong&gt; is about &lt;code&gt;toString()&lt;/code&gt;. This method should only be used for debugging
or logging purposes.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;StringBuilder&lt;/code&gt; class gets this wrong--its &lt;code&gt;toString()&lt;/code&gt; method is used for
programmatic access to the string that is being built. It should probably have
another method called &lt;code&gt;build()&lt;/code&gt; to provide programmatic access, and leave
&lt;code&gt;toString()&lt;/code&gt; for logging purposes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Item 11&lt;/strong&gt; is about &lt;code&gt;clone()&lt;/code&gt;. To be frank, I find the &lt;code&gt;Cloneable&lt;/code&gt; interface
confusing, and I haven't run into a good use for it.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Item 12&lt;/strong&gt; is about &lt;code&gt;compareTo()&lt;/code&gt;. The hard thing with &lt;code&gt;compareTo()&lt;/code&gt; is that
it's not particularly explicit about what the "natural" ordering means. By
contrast, a &lt;code&gt;Comparator&amp;lt;&amp;gt;&lt;/code&gt; can have a name which gives developers more
information about how the comparison is done. This explicit information is
probably good.&lt;/p&gt;
&lt;p&gt;As of Java 7, if you break the general contract for comparisons, an exception
will be thrown.&lt;/p&gt;</description><author>Samuel Taylor</author><guid isPermaLink="true">https://www.samueltaylor.org/articles/effective-java.html?utm_source=rss&amp;utm_campaign=st-blog-feed</guid><pubDate>Sat, 27 Jun 2015 16:44:53 GMT</pubDate></item><item><title>Hackathon report: Hack@Teal 2015</title><link>https://www.samueltaylor.org/articles/hackteal-2015.html?utm_source=rss&amp;utm_campaign=st-blog-feed</link><description>&lt;p&gt;My friend &lt;a href="http://matttinsley.org/"&gt;Matt Tinsley&lt;/a&gt; and I were both RA's in Teal
Resdiential College from Fall 2014 to Spring 2015. We are also both big fans of
hackathons. Matt had the idea for and led the organization of a hackathon for
Teal residents. I helped him out with logistics, and we worked on a project in
the time we weren't doing organizer-y things.&lt;/p&gt;
&lt;p&gt;The first two sections of this article relate to organizing the event, and the
third is about the project I worked on.&lt;/p&gt;
&lt;h2&gt;Successes&lt;/h2&gt;
&lt;p&gt;Lots of things went well.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Learning&lt;/strong&gt; -- Many people during demos said something to the effect of,
  "I've never done anything like this project before today. I learned so much."
  Our faculty master was impressed with how much people were able to learn,
  which was good seeing as he funded much of the event. Education was also a
  huge reason we wanted to have the event, so it was great to see our efforts
  pay off.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Team/idea formation&lt;/strong&gt; -- At the beginning of the event, we had some time for
  individuals who came to the event to find a team. Matt and I stood in a circle
  with the individuals, and we all went around and said an idea we had. This
  format worked well; the four people we had formed two teams. I would recommend
  that organizers bring some simple ideas for people to work on; both of my
  ideas ended up getting used.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Venue&lt;/strong&gt; -- Teal allowed us to use the media room, which had ample space. We
  were also able to bring over plenty of tables from a neighboring classroom.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Google forms&lt;/strong&gt; -- good choice for our voting needs. I could imagine that for
  larger hackathons, there would be too many votes to use Google forms, but it
  was just what we needed for how many participants we had.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Food&lt;/strong&gt; -- We had ample food, people seemed to like it well enough.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hosting&lt;/strong&gt; -- We had one team who wanted to do some stuff with web
  technologies, but didn't have much of an idea what they were doing. I spun up
  a VPS through &lt;a href="https://www.digitalocean.com/?refcode=3dc2cdcca705"&gt;Digital
  Ocean&lt;/a&gt;, and &lt;a href="http://www.wescossick.com/"&gt;Wes
  Cossick&lt;/a&gt; explained a few basic things to them.
  Like that, they were off!&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Hardships&lt;/h2&gt;
&lt;p&gt;A few things were less than perfect.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Staying through the night&lt;/strong&gt; -- I wish more people had chosen to stay through
  the night. Around 4 or 5 am, the room started to feel dead.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Judging&lt;/strong&gt; -- Our faculty master did a great job of judging, but I think it
  would have been cool to have gotten a panel of judges rather than just one
  person.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;My project&lt;/h2&gt;
&lt;p&gt;Matt and I worked on &lt;a href="https://github.com/ssaamm/emoji-predictor"&gt;Emoji
Predictor&lt;/a&gt;. If you've ever used a
smartphone keyboard that suggests words as you type, you'll understand what it
is. Our project suggests relevant emojis for you to use in your text messages.&lt;/p&gt;
&lt;p&gt;We started with a database of all Matt's text messages. This would be our
"corpus", or the body of text we would use to make inferences about which emojis
should be used with which kinds of messages.&lt;/p&gt;
&lt;p&gt;While making an iOS keyboard would have been really cool, we wanted to make a
proof of concept and focus on the part of the project we found interesting:
getting from a string to the emojis most relevant to it. We decided to make a
web UI. I whipped up a simple application using Python, Flask, and JavaScript
(our code can be found on
&lt;a href="https://github.com/ssaamm/emoji-predictor"&gt;GitHub&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;While I was working on the UI side of things, Matt started working on the
recommendation engine using Python Natural Language Toolkit. While he worked on
that, I decided to work on a different implementation of a recommendation
engine. I loaded all of Matt's sent messages which contained emojis into
Elasticsearch and ran a query on that index using user input. This basic
implementation ended up working decently enough.&lt;/p&gt;
&lt;p&gt;Matt ended up having tons of trouble with Python and unicode, so for demo
purposes we went with my implementation. I thought our product was pretty neat.&lt;/p&gt;
&lt;p&gt;Because it relied on Matt's personal information, a live demo unfortunately
isn't up anywhere.&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Despite a few minor problems, Hack@Teal went very well. I was glad to help, and
I'd love to take part in organizing more hackathons. Because it was a small
event, Matt and I were able to hack on our own project, which was fun and
educational.&lt;/p&gt;
&lt;p&gt;If you want more information (especially about other people's projects), please
see the official website for Hack@Teal 2015, &lt;a href="http://hackteal.me/"&gt;hackteal.me&lt;/a&gt;.&lt;/p&gt;</description><author>Samuel Taylor</author><guid isPermaLink="true">https://www.samueltaylor.org/articles/hackteal-2015.html?utm_source=rss&amp;utm_campaign=st-blog-feed</guid><pubDate>Sat, 27 Jun 2015 16:44:53 GMT</pubDate></item><item><title>Hackathon report: HackTX 2014</title><link>https://www.samueltaylor.org/articles/hacktx-2014.html?utm_source=rss&amp;utm_campaign=st-blog-feed</link><description>&lt;h2&gt;Idea&lt;/h2&gt;
&lt;p&gt;Most college students are aware that registering for classes can be a real pain.
At Baylor, we don't have a waitlist on many of our classes. If you fail to get
into a class, you are doomed to logging in several times a day and hoping a seat
is open. This process is a waste of time; we wanted to automate it.
&lt;a href="http://coursewatch.me/"&gt;CourseWatch&lt;/a&gt; makes registering for classes suck less.&lt;/p&gt;
&lt;p&gt;We thought about creating a mobile app that would run in the background on
users' phones. Such an app would require no infrastructure on our end, which
would be great. However, it would require users to download the app and enter
their login credentials. We decided to go with an SMS-based solution. Users
would text us a course number, and we would text them once their class opened
up. Because signing up was as simple as sending a text, this option would have
low friction, which is good for user acquisition.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.hackerleague.org/hackathons/hacktx-2014/hacks/course-watch"&gt;Here's the project page on
HackerLeague&lt;/a&gt;,
which has some basic information about the project.&lt;/p&gt;
&lt;h2&gt;Project&lt;/h2&gt;
&lt;p&gt;I set up a private GitHub repository on my account and added Wes and Evan as
contributors.&lt;/p&gt;
&lt;p&gt;After we found a work space and set up our laptops/devices Wes started
working on creating the screen scraper, Evan started researching other colleges'
registration systems, and I started setting up our server. We decided
to use Microsoft Azure because the Azure team was offering free hosting. I set
up an Ubuntu server with Apache, MySQL, and PHP.&lt;/p&gt;
&lt;p&gt;Wes helped me set up &lt;a href="http://dploy.io/"&gt;dploy.io&lt;/a&gt; to deploy our code
automatically from the master branch of our repository. I'd not used a
continuous deployment service before and was pleased by the ease with which it
let us deploy our code. A pitfall with using this service was that because our
changes to master were automatically deployed, it was easy to get sloppy and
push untested code to master in order to test it on our server. This problem is
our own fault and only requires more discipline to fix. Within a hackathon,
though, it was not a major issue.&lt;/p&gt;
&lt;p&gt;Once the server was set up, I got to work handling inbound SMS messages. I had
experience with using Twilio for SMS from HackTX 2013 and chose to use it again
because it's easy to use and inexpensive.&lt;/p&gt;
&lt;p&gt;After a few minutes of work, Evan finished with his research and wanted to
continue helping. We didn't have a clear design at that point, so I didn't know
what he could work on. As Wes continued to work on the screen scraper, I spread
out a napkin and started drawing the system out. Through this process, I
identified three main areas: notification subscription (which I was working on),
screen scraping (which Wes was working on), and notifying users. Being that
nobody was working on notifying users, Evan started working on that.&lt;/p&gt;
&lt;p&gt;Evan had never used PHP before, so he needed some direction. He sat at the
keyboard, and I sat next to him. Within an hour or two, he had figured out
enough PHP to be dangerous, so I moved to work on subscription through SMS.&lt;/p&gt;
&lt;p&gt;Wes sort of reverse engineered BearWeb, which was an interesting and tedious
process. He opened up &lt;a href="http://www.charlesproxy.com/"&gt;Charles&lt;/a&gt; and clicked around
Baylor's internal course registration website. He would then perform the same
requests in PHP using curl. After several moments where everything seemed
hopeless, he eventually got everything figured out.&lt;/p&gt;
&lt;p&gt;A little after midnight, we had version one done. You could text in a course
number and would get notified a few minutes later that it was open (registration
wasn't open yet, so all seats were open). Wes then set to creating a website for
the product while I worked on adding SendGrid integration so that users could
sign up for notification through email. The SendGrid API was also a pleasure to
work with.&lt;/p&gt;
&lt;p&gt;By around 3:00, the website was looking good enough and we had gotten SendGrid
integration working. At this point, we decided to get some rest. We napped in
the hallway for a few hours then got up to figure out our presentation.&lt;/p&gt;
&lt;h2&gt;Presentation&lt;/h2&gt;
&lt;p&gt;HackTX 2014 did "science-fair style" presentations, which I liked. Each team had
a spot on a table, and a number of judges came around to check out each project.
During this time, participants were encouraged to walk around and check out each
others' projects. I was able to check out a few of the projects near us, but did
not spend much time looking around; I wanted to get feedback on what we had
made.&lt;/p&gt;
&lt;p&gt;We received a lot of positive feedback from judges and other participants.
People liked the high level of polish in our product and presentation. They also
believed we were solving a real problem in a good way. Unfortunately, we
weren't chosen to present during the closing ceremonies. On the plus side, we
won three sponsor awards:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;TripAdvisor prize -- 3 day trip to Boston&lt;/li&gt;
&lt;li&gt;Best use of Microsoft Azure -- Dell XPS U12 laptop&lt;/li&gt;
&lt;li&gt;Best use of SendGrid -- Jawbone MINIJAMBOX&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Summary&lt;/h2&gt;
&lt;p&gt;HackTX 2014 was great. We had fun, built a great product, and won some awesome
prizes.&lt;/p&gt;</description><author>Samuel Taylor</author><guid isPermaLink="true">https://www.samueltaylor.org/articles/hacktx-2014.html?utm_source=rss&amp;utm_campaign=st-blog-feed</guid><pubDate>Sat, 27 Jun 2015 16:44:53 GMT</pubDate></item><item><title>How to: get free WiFi at coffee shops</title><link>https://www.samueltaylor.org/articles/how-to-get-free-wifi.html?utm_source=rss&amp;utm_campaign=st-blog-feed</link><description>&lt;p&gt;Some coffee shops place time limitations on their WiFi. For example, I recently
went to a Panera that had a 30 minute time limit on their WiFi during lunch
hours.&lt;/p&gt;
&lt;p&gt;Getting around such limits isn't difficult. I'm not sure how ethical it is to do
so, so consider this all merely educational information.&lt;/p&gt;
&lt;p&gt;It seems these kinds of systems track you based on your MAC address. If your MAC
address changes, the system thinks of you as a new user. Changing your MAC
address is easy enough (on Linux):&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Figure out what interface you're using.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Run &lt;code&gt;ifconfig&lt;/code&gt; and look for the one that looks like right. Mine was &lt;code&gt;wlan0&lt;/code&gt;.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Change your MAC address&lt;/p&gt;
&lt;p&gt;ifconfig wlan0 down
ifconfig wlan0 hw ether a1:b2:c3:d4:e5:f6
ifconfig wlan0 up&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;For ease of changing, you can make a script that looks something like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#!/bin/bash

ifconfig wlan0 down
ifconfig wlan0 hw ether $1
ifconfig wlan0 up
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And then run it like &lt;code&gt;./change_mac.sh a1:b2:c3:d4:e5:f6&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;If you want to get in touch, email me at sgt@samueltaylor.org. Thanks!&lt;/p&gt;</description><author>Samuel Taylor</author><guid isPermaLink="true">https://www.samueltaylor.org/articles/how-to-get-free-wifi.html?utm_source=rss&amp;utm_campaign=st-blog-feed</guid><pubDate>Sat, 27 Jun 2015 16:44:53 GMT</pubDate></item><item><title>How to: remove Etsy search ads</title><link>https://www.samueltaylor.org/articles/how-to-remove-etsy-search-ads.html?utm_source=rss&amp;utm_campaign=st-blog-feed</link><description>&lt;ol&gt;
&lt;li&gt;Install Greasemonkey or Tampermonkey&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Firefox users:
   &lt;a href="https://addons.mozilla.org/en-us/firefox/addon/greasemonkey/"&gt;Greasemonkey&lt;/a&gt;&lt;br /&gt;
   Chrome users:
   &lt;a href="https://chrome.google.com/webstore/detail/tampermonkey/dhdgffkkebhmkfjojejmpbldmpobfkfo"&gt;Tampermonkey&lt;/a&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Install Etsy Ad Remover&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a href="https://github.com/ssaamm/greasemonkey-scripts/raw/master/Etsy_Ad_Remover.user.js"&gt;Click this link to
   install&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This script simply removes ads from search result on Etsy. If you're curious,
   check out the &lt;a href="https://github.com/ssaamm/greasemonkey-scripts/blob/master/Etsy_Ad_Remover.user.js"&gt;source code on
   GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Implementation&lt;/h2&gt;
&lt;p&gt;Etsy search ads have children with a CSS class of &lt;code&gt;.ad-indicator&lt;/code&gt;. It's
literally one line to remove those. This was a fun way to figure out how to make
the web less annoying through using browser dev tools and Greasemonkey.&lt;/p&gt;
&lt;p&gt;If you have any feedback, please contact me at sgt at this domain. Thanks!&lt;/p&gt;</description><author>Samuel Taylor</author><guid isPermaLink="true">https://www.samueltaylor.org/articles/how-to-remove-etsy-search-ads.html?utm_source=rss&amp;utm_campaign=st-blog-feed</guid><pubDate>Sat, 27 Jun 2015 16:44:53 GMT</pubDate></item><item><title>Notes: Boston Django Meetup, Intro to Flask, 25 June 2015</title><link>https://www.samueltaylor.org/articles/notes-boston-django-25-jun-2015.html?utm_source=rss&amp;utm_campaign=st-blog-feed</link><description>&lt;p&gt;On 25 June 2015, Ned Jackson Lovely spoke about Flask at the Boston Django Users
Meetup Group. I took some notes and am putting them here so I don't lose them;
they may or may not be useful to others. Theses notes are not exhaustive.&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;Functions that are decorated with &lt;code&gt;@flaskapp.route()&lt;/code&gt; should return:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;a string&lt;/li&gt;
&lt;li&gt;a tuple of (response, status, headers)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;flask.Response&lt;/code&gt; / &lt;code&gt;current_app.response_class&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;a WSGI callable&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In theory, your function could return another Flask app, or spit out a WSGI
    callable that generated a massive CSV on the fly and streamed it to the user&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You can do testing:&lt;/p&gt;
&lt;p&gt;def test_splash():
    client = app.test_client()
    response = client.get('/')
    assert response.status_code == 200
    assert 'form' in response.data&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The Werkzeug debugger is awesome&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Defining filters for templates is possible (and ostensibly simple)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Sessions in Flask are interesting&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Session data is serialized to JSON, cryptographically signed, and set in the
  user's browser as a cookie&lt;/li&gt;
&lt;li&gt;Because it's client side, it doesn't matter which datacenter they end up in&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If you write to a "second level" in &lt;code&gt;session&lt;/code&gt;, you need to set
  &lt;code&gt;session.modified = True&lt;/code&gt; for the changes to get written out:&lt;/p&gt;
&lt;p&gt;session['first']['second'] = 'new thing'
session.modified = True&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Flashing is done with sessions, and is useful for displaying those one-time,
  web app-y messages like "Your post was submitted"&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;On a general Python note, contexts (&lt;code&gt;with&lt;/code&gt;/&lt;code&gt;as&lt;/code&gt;) are really cool -- you only
  have to implement two &lt;code&gt;__&lt;/code&gt; methods to get the benefits of them&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Some useful libraries: SQLAlchemy, WTForms&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Blueprints:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Helpful when your app gets bigger&lt;/li&gt;
&lt;li&gt;They're very similar to &lt;code&gt;Flask&lt;/code&gt; objects with an additional "namespace"&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;app.register_blueprint(bp, url_prefix='/counter')&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;To get GET/POST data, use &lt;code&gt;request.values&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Deploying:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;gevent, gunicorn, nginx, ansible  &lt;/li&gt;
&lt;li&gt;supervisor  &lt;/li&gt;
&lt;li&gt;pip freeze&lt;/li&gt;
&lt;/ul&gt;</description><author>Samuel Taylor</author><guid isPermaLink="true">https://www.samueltaylor.org/articles/notes-boston-django-25-jun-2015.html?utm_source=rss&amp;utm_campaign=st-blog-feed</guid><pubDate>Sat, 27 Jun 2015 16:44:53 GMT</pubDate></item><item><title>Notes: Boston Python User Group, Lightning Talks, 22 June 2015</title><link>https://www.samueltaylor.org/articles/notes-boston-python-22-jun-2015.html?utm_source=rss&amp;utm_campaign=st-blog-feed</link><description>&lt;p&gt;On 22 June 2015, the Boston Python User Group had a night of seven lightning
talks. These are notes I took for personal use; they're not a perfect re-telling
of what each talk was about (or even what each talk was called).&lt;/p&gt;
&lt;h2&gt;#1 Python for making connections in groups&lt;/h2&gt;
&lt;h3&gt;Speaker: John Hess&lt;/h3&gt;
&lt;p&gt;John and a friend distant from him in his social graph each ended up being stood
up by friends at the same bar. They decided to sit down and solve the world's
problems. They ended up enjoying their time, so John wanted to find a way to
automate this sort of process.&lt;/p&gt;
&lt;p&gt;The idea is something like this:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A group of people sign up on &lt;a href="https://www.mavenbot.com"&gt;Maven&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;The service selects a group of about 4-6 people and texts them to see if
  they're available&lt;/li&gt;
&lt;li&gt;As people accept or decline invitations to the event, Maven will text more
  people from the group to get them in on the event&lt;/li&gt;
&lt;li&gt;Maven then puts everyone into a group message so they can organize the event&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;John found that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Building stuff is easy in Python&lt;/li&gt;
&lt;li&gt;Python is a Swiss army knife, but it can't do everything (for example, mobile
  development)&lt;/li&gt;
&lt;li&gt;While building stuff is easy, building stuff that is user friendly is &lt;em&gt;really
  hard&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;John kept iterating, putting the product in front of friends, getting
    feedback, and trying new things&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;#2 Django cloud management&lt;/h2&gt;
&lt;h3&gt;Speaker: Robert Paul Chase&lt;/h3&gt;
&lt;p&gt;I was semi-lost on this one. The project was related to genetics somehow, and I
know nothing about computational genetics.&lt;/p&gt;
&lt;p&gt;He built a cloud management platform that lets biologists and researchers (read:
not developers) easily spin up nodes, install necessary software, run their
code, and kill their cluster when they're done with it.&lt;/p&gt;
&lt;h2&gt;#3 &lt;code&gt;.format()&lt;/code&gt;ing without tears&lt;/h2&gt;
&lt;h3&gt;Speaker: Richard Landau&lt;/h3&gt;
&lt;p&gt;The standard &lt;code&gt;str.format()&lt;/code&gt; method in Python will throw a &lt;code&gt;KeyError&lt;/code&gt; if a name
isn't found in the dictionary. Rick made his own function to avoid that problem.
Here's how it works:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Uses a regex to get the names both with and without braces (e.g. "{foo}" and
  "foo")&lt;/li&gt;
&lt;li&gt;Zips those two arrays together (to get &lt;code&gt;('foo', '{foo}'), ('bar', '{bar}'),
  ('baz', '{baz}')&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;Constructs a dictionary from that array (the format of the tuples will work
  with &lt;code&gt;dict()&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;At first, it seemed to me like another way to implement this behavior would be
to provide &lt;code&gt;.format()&lt;/code&gt; with a dictionary that, instead of throwing a &lt;code&gt;KeyError&lt;/code&gt;
when encountering an unknown key, would return a modified version of the key
which was asked for. I tried to do that, and it turns out that doesn't work&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;class FancyDict(object):
    def __init__(self, dictionary):
        self.__dictionary = dictionary

    def __getitem__(self, key):
        try:
            return self.__dictionary[key]
        except KeyError:
            return '{' + key + '}'

    def keys(self):
        return self.__dictionary.keys()

if __name__ == '__main__':
    params = { 'foo': 'this is foo', 'bar': 'this is bar', 'baz': 'this is baz' }
    print '{foo} {bar} {baz}'.format(**params)
    # this is foo this is bar this is baz

    params = { 'foo': 'this is foo', 'bar': 'this is bar' }
    print '{foo} {bar} {baz}'.format(**params)
    # KeyError: 'baz'

    params = FancyDict({ 'foo': 'this is foo', 'bar': 'this is bar' })
    print '{foo} {bar} {baz}'.format(**params)
    # KeyError: 'baz'
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;str.format()&lt;/code&gt; gets the keys of the dictionary and will throw a &lt;code&gt;KeyError&lt;/code&gt; if
any of the strings in curly braces are absent.&lt;/p&gt;
&lt;h2&gt;#4 Test all the data&lt;/h2&gt;
&lt;h3&gt;Speaker: Eric J Ma&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Testing data is important because you have some assumptions about it that may
  not always be correct&lt;/li&gt;
&lt;li&gt;He talked some more about how to do that using PyTest&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;#5 Visualizing Yeast ChIP-Seq data&lt;/h2&gt;
&lt;h3&gt;Speaker: Luis Soares&lt;/h3&gt;
&lt;p&gt;I was completely out of my league on the domain of this one, which was something
related to biology.&lt;/p&gt;
&lt;p&gt;It looked like a neat web-based visualization project.&lt;/p&gt;
&lt;h2&gt;#6 Payment reform&lt;/h2&gt;
&lt;h3&gt;Speaker: James Santucci&lt;/h3&gt;
&lt;p&gt;I wasn't super familiar with the domain (statistics).&lt;/p&gt;
&lt;p&gt;The big takeaway was that how we measure value affects how much value we
observe. I'm not sure what that means.&lt;/p&gt;
&lt;h2&gt;#7 Hypothesis: property-based testing&lt;/h2&gt;
&lt;h3&gt;Speaker: Matt Bachmann&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Hypothesis is a Python library inspired by Haskell's QuickCheck&lt;/li&gt;
&lt;li&gt;You put a decorator on your test to say what kind of data it takes&lt;/li&gt;
&lt;li&gt;It works with most testing frameworks&lt;/li&gt;
&lt;li&gt;You write a small amount of code, but get a big amount of functionality tested&lt;/li&gt;
&lt;/ul&gt;</description><author>Samuel Taylor</author><guid isPermaLink="true">https://www.samueltaylor.org/articles/notes-boston-python-22-jun-2015.html?utm_source=rss&amp;utm_campaign=st-blog-feed</guid><pubDate>Sat, 27 Jun 2015 16:44:53 GMT</pubDate></item></channel></rss>